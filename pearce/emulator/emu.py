#!/bin/bash
"""The Emu object esentially wraps the GPy gaussian process code. It handles building, training, and predicting."""

import warnings
from itertools import izip
from collections import OrderedDict
from os import path
import sys
from time import time
import cPickle as pickle
from abc import ABCMeta, abstractmethod
from ast import literal_eval

import numpy as np
import h5py
#import george
#from george.kernels import *
from GPy.models import GPRegression, GPKroneckerGaussianRegression
from .gp_kronecker_gaussian_regression_var import GPKroneckerGaussianRegressionVar
from GPy.kern import *
import scipy.optimize as op
from scipy.interpolate import interp1d
from scipy.spatial import KDTree
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.kernel_ridge import KernelRidge
from sklearn.svm import SVR
from sklearn.linear_model import LinearRegression
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

#DIR_PATH = path.abspath(path.dirname(__file__))
# TODO these are kernels now
#DEFAULT_METRIC_PICKLE_FNAME= path.join(DIR_PATH, 'default_metrics.pkl')
#DEFAULT_METRIC_NH_PICKLE_FNAME= path.join(DIR_PATH, 'default_nh_metrics.pkl')

# TODO with the addition of Nashiville Hot, this object doesn't contain as many general features as I'd like.
# Worth considering how I rebalance some of these features.
# Also worth considering if I want to have a data management obj and an emulator object, and combine them into Emus.
# seems like that may actually be awful.
class Emu(object):
    '''Main Emulator base class. Cannot itself be instatiated; can only be accessed via subclasses.
       controls all loading, manipulation, and emulation of data.
    '''

    __metaclass__ = ABCMeta
    valid_methods = {'gp', 'svr', 'gbdt', 'rf', 'krr',
                     'linear', 'nn'}  # could add more, coud even check if they exist in sklearn
    skl_methods = {'gbdt': GradientBoostingRegressor, 'rf': RandomForestRegressor, \
            'svr': SVR, 'krr': KernelRidge, 'linear': LinearRegression, 'nn': MLPRegressor}

    def __init__(self, filename, method='gp', hyperparams={}, fixed_params={},\
                        downsample_factor = 1.0, custom_mean_function = None):
        '''
        Initialize the Emu
        :param filename:
            A .hdf5 file containing the training data, in the format of those generated by trainer.py
        :param method:
            Emulation method. Valid methods are 'gp', 'svr', 'gbdt', 'rf', and 'krr'. Default is 'gp'. GP is
            conducted by george, all others are executed by sklearn. Kernel based sklearn methods use a george kernel.
        :param hyperparams:
            Hyperparameters for the emulator. Gp hyperparams are passed into george, others are passed into
            sklearn. A special hyperparam is 'metric', which determines the metric for kernel-based methods.
            See documentation for a full list of hyperparameters.
             Default is {}.
        :param fixed_params:
            Parameters to hold fixed during training. Key is the name of the param, value if the value to hold fixed.
            The only parameters that can be fixed are 'cosmo', 'HOD', 'r', and 'z'. 'r' and 'z' can be fixed to floats
            of scale (distance in Mpc, angle in degrees, etc) and redshift respectively.
            Cosmo and HOD can only be fixed to an integer number, representing the index of the cosmo/HOD to hold fixed
            across HODs/Cosmologies respectively. Multiple fixed params can be specified.
             Default is {}.
        :param independent_variable:
            Indepent variable to emulate. Default is None, which just emulates the iv in the training data
            directly. Presently the only acceptable option is 'r2', which emulates r^2 times the
            parameter in the training data.
        '''

        assert method in self.valid_methods


        self.method = method
        self.filename = filename

        self.fixed_params = fixed_params
        self._downsample_factor = downsample_factor

        self.load_training_data(filename, custom_mean_function)
        self.build_emulator(hyperparams)

    ###Data Loading and Manipulation####################################################################################
    # This function is a little long, but I'm not certain there's a need to break it up
    # it's shorter than it used to be, too.
    def get_data(self, filename, fixed_params, attach_params = False, remove_nans = True):
        """
        Read data in the format compatible with this object and return it.

        :param filename:
            A .hdf5 file containing the training data, in the format of those generated by trainer.py
        :param fixed_params:
            Parameters to hold fixed during training. Key is the name of the param, value if the value to hold fixed.
            The only parameters that can be fixed are 'cosmo', 'HOD', 'r', and 'z'. 'r' and 'z' can be fixed to floats
            of scale (distance in Mpc, angle in degrees, etc) and redshift respectively.
            Cosmo and HOD can only be fixed to an integer number, representing the index of the cosmo/HOD to hold fixed
            across HODs/Cosmologies respectively. Multiple fixed params can be specified.
        :return: x, y, yerr, ycov, all numpy arrays.
                 x is (n_data_points, n_params)
                 y is (n_data_points, ), yerr is (n_data_points)
                 and ycov (n_data_points, n_scale_bins, n_scale_bins), a "list" of covaraince matrices,
                 to do with what you will
        """
        assert path.isfile(filename)
        # fixed params can only fix an hod index, cosmo index, or z or r
        assert len(fixed_params) <= 4
        assert all(key in {'cosmo', 'HOD', 'z', 'r', 'rmin'} for key in fixed_params)

        for key in ['cosmo', 'HOD']:
            if key in fixed_params:
                assert type(fixed_params[key]) is int

        f = h5py.File(filename, 'r')

        # get global attributes from the file
        cosmo_param_names = f.attrs['cosmo_param_names']
        hod_param_names = f.attrs['hod_param_names']
        try:
            cosmo_param_vals = f.attrs['cosmo_param_vals']
            hod_param_vals = f.attrs['hod_param_vals']
        except KeyError:
            cosmo_param_vals = np.array(f['attrs/cosmo_param_vals'])
            hod_param_vals = np.array(f['attrs/hod_param_vals'])

        fixed_cosmo = 'cosmo' in fixed_params or cosmo_param_vals.shape[0] == 1
        fixed_hod = 'HOD' in fixed_params or hod_param_vals.shape[0] == 1

        scale_factors = f.attrs['scale_factors']
        redshift_bin_centers = 1.0/scale_factors - 1 # emulator works in z, sims in a.
        if 'z' in fixed_params:
            assert fixed_params['z'] in redshift_bin_centers

        scale_bins = f.attrs['scale_bins']
        scale_bin_centers = (scale_bins[1:] + scale_bins[:-1])/2.0 if scale_bins is not None else None

        rmin = fixed_params['rmin'] if 'rmin' in fixed_params else 0.0
            # instead of fixing values, just ensure values are greater than this values
        gt_rmin = scale_bin_centers > rmin
        scale_bin_centers = scale_bin_centers[gt_rmin]

        if 'r' in fixed_params:
            # this wil also fale if scb is None. but you can't fix when it's none anyway so.
            # may wanna have a friendlier error message htough.
            assert np.any(np.abs(fixed_params['r'] - scale_bin_centers) < 1e-4) # may need to include a fudge factor here
            r_idx = np.argmin(np.abs(fixed_params['r'] -  scale_bin_centers))


        # construct ordered_params
        # ordered_params is an ordered dict whose keys are the parameters in the
        # order they are in in the data. The values are their bounds in the training data
        if fixed_hod and not fixed_cosmo:
            # Why not?
            #if 'cosmo' in fixed_params:
            #    raise ValueError("Can't fix both HOD and cosmology!")
            min_max_vals = zip(cosmo_param_vals.min(axis=0), cosmo_param_vals.max(axis=0))
            ordered_params = OrderedDict(izip(cosmo_param_names, min_max_vals))
        elif fixed_cosmo and not fixed_hod:
            min_max_vals = zip(hod_param_vals.min(axis=0), hod_param_vals.max(axis=0))
            ordered_params = OrderedDict(izip(hod_param_names, min_max_vals))
        elif not fixed_hod and not fixed_cosmo:
            op_names = list(cosmo_param_names[:])
            op_names.extend(hod_param_names)

            min_max_vals = zip(np.r_[cosmo_param_vals.min(axis=0), hod_param_vals.min(axis=0)], \
                               np.r_[cosmo_param_vals.max(axis=0), hod_param_vals.max(axis=0)])
            ordered_params = OrderedDict(izip(op_names, min_max_vals))
        else:
            ordered_params = OrderedDict()

        # NOTE if its single_valued, may have to fudge this somehow?
        if 'z' not in fixed_params:
            ordered_params['z'] = (np.min(redshift_bin_centers), np.max(redshift_bin_centers))

        if 'r' not in fixed_params:
            ordered_params['r'] = (np.log10(np.min(scale_bin_centers)), np.log10(np.max(scale_bin_centers)))

        if attach_params: #attach certain parameters to the object
            self.obs = f.attrs['obs']
            self.redshift_bin_centers = redshift_bin_centers
            self.scale_bin_centers = scale_bin_centers
            self.n_bins = len(scale_bin_centers) if (scale_bin_centers is not None) and ('r' not in fixed_params) else 1
            self._ordered_params = ordered_params
        else:
            # return them
            info = {'obs': f.attrs['obs'],
                    'rbc': redshift_bin_centers,
                    'sbc': scale_bin_centers,
                    'n_bins': len(scale_bin_centers) if (scale_bin_centers is not None) and ('r' not in fixed_params) else 1,
                    'ordered_params': ordered_params
                    }

        # append files to a list, then concatenate at the end
        x = []
        y = []
        ycov = []

        # book keeping vars.
        # only want to warn the user once.
        #give_warning = False
        # these can be useful for debugging
        #num_skipped = 0
        num_used = 0

        for cosmo_group_name, cosmo_group in f.iteritems():
            # we're fixed to a particular cosmology #
            if cosmo_group_name == 'attrs':
                continue
            cosmo_no = int(cosmo_group_name[-2:])
            if 'cosmo' in fixed_params and cosmo_no != fixed_params['cosmo']:
                    continue
            for sf_group_name, sf_group in cosmo_group.iteritems():
                z = 1.0/float(sf_group_name[-5:]) - 1.0

                if 'z' in fixed_params and np.abs(z-fixed_params['z'])> 1e-3:
                    continue

                obs_dset = sf_group['obs'][()]

                cov_dset = []
                for i in xrange(obs_dset.shape[1]):
                    cov_dset.append(sf_group['cov'][:, i,i])

                cov_dset = np.vstack(cov_dset).T

                cosmo = cosmo_param_vals[cosmo_no, :]
                # efficiency note. If I don't iterate over the datasets, just the indicies,
                # I avoid loading them from disk in fixed HOD scenarios
                # Those will be rare enough for now that I don't care.
                counter = 0
                t0 = time()
                for HOD_no, (_obs, _cov) in enumerate(izip(obs_dset, cov_dset)):
                    if "HOD" in fixed_params and HOD_no != fixed_params['HOD']:
                        continue
                    #if any(np.any(np.isnan(arr)) for arr in [_obs, _cov]):
                        # skip NaN points. May wanna change this behavior.
                        #pass
                        #give_warning = True
                        #num_skipped += 0#1
                        #continue
                        #_obs[np.isnan(_obs)] = -2
                        #_cov[np.isnan(_cov)] = 1e3 # made up values for now

                    HOD = hod_param_vals[HOD_no, :]

                    params = []
                    # I wonder if this is annoyingly inefficient. Probably not a huge deal.
                    if not fixed_cosmo:
                        params.extend(list(cosmo))
                    if not fixed_hod:
                        params.extend(list(HOD))
                    if 'z' not in fixed_params:
                        params.append(z)
                    # handle fixed r differently than the others

                    if 'r' in fixed_params:
                        params = np.array(params)

                        x.append(params)

                        #we hve to transform the data (take a log, multiply, etc)
                        # TODO this may not work with things like r2 anymore
                        # _o, _c = self._iv_transform(independent_variable, _obs, _cov)
                        y.append(np.array([_obs[r_idx]]))
                        ycov.append(np.array(_cov[r_idx,]))# r_idx]))

                    else:
                        _params = np.zeros((scale_bin_centers.shape[0], len(params) + 1))
                        _params[:, :-1] = params
                        _params[:, -1] = np.log10(scale_bin_centers)
                        x.append(_params)

                        #_o, _c = self._iv_transform(independent_variable, _obs, _cov)
                        y.append(_obs[gt_rmin])
                        ycov.append(np.diag(_cov[gt_rmin]))#, :][:, gt_rmin])

                    num_used += 1

        f.close()

        x, y, _ycov = np.vstack(x), np.hstack(y), np.dstack(ycov)

        if (np.any(np.isnan(_ycov))  or np.any(np.isnan(y)) ) and remove_nans:
            y_nans = np.isnan(y)
            #print 'y_nans', np.sum(y_nans)
            #ycov_nans = np.sum(np.isnan(_ycov), axis = 1).astype(bool).reshape((-1,))
            #print 'ycov_nans', np.sum(ycov_nans)
            nan_idxs = y_nans#np.logical_or(y_nans ,ycov_nans ) 
            num_skipped = np.sum(nan_idxs)

            x = x[~nan_idxs]#, :]
            y = y[~nan_idxs]
            ycov_list = []

            for i in xrange(_ycov.shape[-1]):
                mat = _ycov[:,:,i]
                idxs = nan_idxs[i*mat.shape[0]: (i+1)*mat.shape[0]]
                ycov_list.append(mat[~idxs,:][:, ~idxs])

            ycov = ycov_list#np.dstack(ycov_list)

            warnings.warn('WARNING: NaN detected. Skipped %d points in training data.' % (num_skipped))

        else:
            ycov = _ycov.T 

        # stack so xs have shape (n points, n params)
        # ys have shape (npoints)
        # and ycov has shape (n_bins, n_bins, n_points/n_bins)
        if attach_params:
            return x, y, ycov    
        else:
            return x,y, ycov, info

    def load_training_data(self, filename, custom_mean_function = None):
        """
        Read the training data for the emulator and attach it to the object.

        :param filename:
            A .hdf5 file conatining training data in the format generated by trainer.py
        :return: None
        """

        # make sure we attach metadata to the object
        x, y, ycov = self.get_data(filename, self.fixed_params, attach_params=True)

        # store the data loading args, if we wanna reload later
        # useful ofr sampling the training data

        # whiten the training data
        self._x_mean, self._x_std = x.mean(axis = 0), x.std(axis = 0)
        self._y_mean, self._y_std = 0.0, 1.0#y.mean(axis = 0), y.std(axis = 0)

        ycov_list = []
        for yc in ycov: 
            ycov_list.append(yc/(np.outer(self._y_std+1e-5, self._y_std+1e-5)))

        self.x = self._whiten(x)[0]
        self.y = self._whiten(y, arr ='y')[0].reshape((-1, 1))

        # TODO differnet hyperparams depending on what this is.
        self.mean_function = self._make_custom_mean_function(custom_mean_function)
        self.y-=self.mean_function(self.x)

        # in general, the full cov matrix will be too big, and we won't need it. store the diagonal, and
        # an average
        #split_ycov = np.dsplit(ycov, ycov.shape[-1])
        #fullcov = block_diag(*[yc[:,:,0] for yc in split_ycov])

        if type(ycov) is not list:
            self.yerr = np.sqrt(np.hstack(np.diag(syc) for syc in ycov))
        else:
            self.yerr = np.sqrt(np.hstack(np.diag(np.array(syc)) for syc in ycov))
        self.yerr = self.yerr.reshape((-1,1))
        #self.yerr = np.hstack([yerr for i in xrange(self.x.shape[0] / fullcov.shape[0])])
        #compute the average covaraince matrix
        self.ycov = np.zeros((self.n_bins, self.n_bins))
        n_right_shape = 0

        #TODO this bugs out for different implementatiosn
        for yc in ycov:
            if yc.shape[0] != self.n_bins:
                continue
            elif np.any(np.isnan(yc)):
                continue

            n_right_shape+=1
            self.ycov+=yc

        self.ycov/=n_right_shape

        ndim = self.x.shape[1]
        self.emulator_ndim = ndim  # The number of params for the emulator is different than those in sampling.

    def _whiten(self, x, arr = 'x'):
        """
        Whiten array x according to x_mean, x_std
        :param x:
            array to whiten
        :return:
            white_x, a whiened version of x, and None
        """
        # TODO check for dimensionality, existence of the means, etc
        if arr == 'x':
            return (x - self._x_mean)/(self._x_std + 1e-5), None
        elif arr == 'y':
            return (x - self._y_mean)/(self._y_std + 1e-5), None
        else:
            raise NotImplementedError
    # TODO bake this into Gpy, or remove altogether tbh
    def _make_custom_mean_function(self, custom_mean_function =None):
        """
        Generate a custom mean function to make training better behaved (in theory)
        """
        # TODO docs

        if custom_mean_function is None:
            return lambda x: 0

        elif custom_mean_function == 'linear' or custom_mean_function == 1:
            self._mean_func = LinearRegression() #TODO hyperparams
            self._mean_func.fit(self.x, self.y)

            return self._mean_func.predict

        elif type(custom_mean_function) is int and custom_mean_function > 0: # TODO would like to take a dict here maybe, for kwargs
            self._mean_func = make_pipeline(PolynomialFeatures(custom_mean_function), LinearRegression())
            self._mean_func.fit(self.x, self.y)

            return self._mean_func.predict

        else:
            raise NotImplementedError #TODO add something better! 

    def get_param_names(self):
        """
        Helper function that returns the names of the parameters in the emulator.
        :return: names, a list of parameter names (in order)
        """
        return self._ordered_params.keys()

    def get_param_bounds(self, param):
        """
        Return the emulator bounds for parameter param. Raises a ValueError if it can't be found.
        :param param:
            String, the name of the parameter to return bounds for.
        :return: bounds, a 2 element tuple with the lower and higher bounds of point param.
        """
        try:
            return self._ordered_params[param]
        except KeyError:
            raise KeyError("Parameter %s could not be found." % param)

    # TODO Should I unify some syntax between this and the one below?
    def check_param_names(self, param_names, ignore=[]):
        """
        Checks that all parameter names in param_names are defined in the emulator, and vice versa.
        :param param_names:
            List of strings of parameter names to compare to _ordered_params
        :param ignore"
            A list of parameters to ignore. There are many use cases where parameters like 'r' are definedi n the
            emulator but not used in the emulator, so we wouldn't want params to define them.
        :return:
            True if all param_names are in ordered_params, and vice verse. False otherwise
        """
        op_set = set(self._ordered_params.iterkeys())
        ip_set = set(param_names)

        for ig in ignore:
            if ig in op_set:
                op_set.remove(ig)
            if ig in ip_set:
                ip_set.remove(ig)

        return len(op_set ^ ip_set) == 0

    def _check_params(self, params):
        """
        Assert that all keys in params are defined in ordered params, and vice versa. Raises an AssertionError otherwise.
        Will also raise a warning if trying to emulate out of bounds.
        :param params:
            Dictionary of params, where the key is the name and the value is the value it holds. Value can also
            be a numpy array.
        :return: None
        """
        try:
            assert self.check_param_names(params.keys())
        except AssertionError:
            output = "The input_params passed into get_data did not match those the Emu knows about. \
                                              It's possible fixed_params is missing a parameter, or you defined an extra one. \
                                              Additionally, orded_params could be wrong too!\n"

            op_set = set(self._ordered_params.iterkeys())
            ip_set = set(params.iterkeys())

            ip_not_op = ip_set - op_set
            op_not_ip = op_set - ip_set

            if ip_not_op:
                output += 'Param %s was in the input but not the training data.\n' % list(ip_not_op)[0]
            if op_not_ip:
                output += 'Param %s was in the training data but not the input.\n' % list(op_not_ip)[0]

            raise AssertionError(output)

        for pname, (plow, phigh) in self._ordered_params.iteritems():
            try:
                # check if they're in bounds, else raise an informative warning
                val = params[pname]
                # TODO wish i didn't have to hardcode this
                # NOTE insert from merge, not sure if bad
                #if pname == 'r':
                #    val = np.log10(val)

                assert np.all(plow <= val) and np.all(val <= phigh)
            except AssertionError:
                if type(val) is float:
                    warnings.warn("Emulator value for %s %.3f is outside the bounds (%.3f, %.3f) of the emulator." % (
                        pname, val, plow, phigh))
                else:
                    warnings.warn("One value for %s is outside the bounds (%.3f, %.3f) of the emulator." % (
                        pname, plow, phigh))

    def _iv_transform(self, independent_variable, obs, cov=None):
        """
        Depreceated. # TODO remove
        Independent variable tranform. Helper function that consolidates this operation all in one place.
        :param independent_variable:
            Which iv to transform to. Current options are None (just take log) and r2.
        :param obs:
            Observable to transform (xi, wprp, etc.)
        :param cov:
            Covariance of obs. Optional.
        :return:
            y, y_cov the transformed iv's for the emulator. If cov is none, only return y.
        """
        # NOTE this invalidates old training data
        if independent_variable is None or independent_variable == 'wt':
            # y = np.log10(obs)
            # Approximately true, may need to revisit
            # yerr[idx * NBINS:(idx + 1) * NBINS] = np.sqrt(np.diag(cov)) / (xi * np.log(10))
            # y_cov = cov/np.outer(obs * np.log(10), obs*np.log(10))
            y = obs
            y_cov = cov

        elif independent_variable == 'r2':  # r2xi
            y = obs * self.scale_bin_centers * self.scale_bin_centers
            y_cov = cov * np.outer(self.scale_bin_centers, self.scale_bin_centers)
        else:
            raise ValueError('Invalid independent variable %s' % independent_variable)

        # if independent_variable == 'bias':
        #    y[idx * NBINS:(idx + 1) * NBINS] = xi / xi_mm
        #    ycovs.append(cov / np.outer(xi_mm, xi_mm))
        if cov is not None:
            return y, y_cov
        return y

    def _sort_params(self, t, argsort=False):
        """
        Sort the parameters in a defined away given the orderering.
        :param t:
            Parameter vector to sort. Should have dims (N, N_params) and be in the order
            defined by ordered_params
        :param argsort:
            If true, return indicies that would sort the array rather than the sorted array itself.
            Default is False.
        :return:
            If not argsort, returns the sorted array by column and row. 
            If argsort, return the indicies that would sort the array.
        """
        if t.shape[0] == 1:
            if argsort:
                return np.array([0])
            return t  # a single row array is already sorted!

        # the sorting procedure is black magic. Don't touch unless you're smarter than me.
        if argsort:  # returns indicies that would sort the array
            # weird try structure because this view is very tempermental!
            try:
                idxs = np.argsort(t.view(','.join(['float64' for _ in xrange(min(t.shape))])),
                                  order=['f%d' % i for i in xrange(min(t.shape))], axis=0)
            except ValueError:  # sort with other side
                idxs = np.argsort(t.view(','.join(['float64' for _ in xrange(max(t.shape))])),
                                  order=['f%d' % i for i in xrange(max(t.shape))], axis=0)

            return idxs[:, 0]

        try:
            t = np.sort(t.view(','.join(['float64' for _ in xrange(min(t.shape))])),
                        order=['f%d' % i for i in xrange(min(t.shape))], axis=0).view(np.float)
        except ValueError:  # sort with other side
            t = np.sort(t.view(','.join(['float64' for _ in xrange(max(t.shape))])),
                        order=['f%d' % i for i in xrange(max(t.shape))], axis=0).view(np.float)

        return t

    ###Emulator Building and Training###################################################################################

    def build_emulator(self, hyperparams):
        """
        Initialization of the emulator from recovered training data. Calls submethods depending on "self.method"
        :param hyperparams
            A dictionary of hyperparameter kwargs for the emulator
        :return: None
        """

        assert 0 < self._downsample_factor <= 1.0
        if self._downsample_factor < 1.0:
            if hasattr(self, "x"):
                self._downsample_data(self._downsample_factor, self.x, self.y, self.yerr, attach=True)
            else: # edgecase. Could get around this with a ton of kwargs...
                self._downsample_data(self._downsample_factor, self.x1, self.x2, self.y, self.yerr, attach=True)

        if self.method == 'gp':
            self._build_gp(hyperparams)
            if 'optimize' in hyperparams and hyperparams['optimize']:
                self.train_metric()
        else:  # an sklearn method
            self._build_skl(hyperparams)

    @abstractmethod
    def _downsample_data(self,downsample_factor, x, y, yerr, attach=False):
        pass

    @abstractmethod
    def _build_gp(self, hyperparams):
        pass

    @abstractmethod
    def _build_skl(self, hyperparams):
        pass

    def _get_default_kernel(self):

        #with open(DEFAULT_METRIC_PICKLE_FNAME, 'r') as f:
        #    default_kernels = pickle.load(f)
        # TODO I should save these under the emu name, so different kernels don't overlap
        f = h5py.File(self.filename, 'r')
        if 'kernel' in f.attrs: 
           kernel_dict =f.attrs['kernel']
        else:
            raise KeyError("No default saved for this observable!")
        f.close()

        return self._kernel_from_dict(kernel_dict)

        # this has problems for xied binning schemees...
        # Don't know how to make this work with the new kernel schemes, or cosmology.

        # if type(metric) is list:
        #
        #     for bin_metric in metric:
        #         for key in self._ordered_params:
        #             if key not in bin_metric:
        #                bin_metric[key] = 1.0
        #
        #         # remove entries for variables that are being held fixed.
        #         for key in self.fixed_params.iterkeys():
        #             if key in bin_metric:
        #                 del bin_metric[key]
        # else:
        #     for key in self._ordered_params:
        #         if key not in metric:
        #            metric[key] = 1.0
        #
        #     # remove entries for variables that are being held fixed.
        #     for key in self.fixed_params.iterkeys():
        #         if key in metric:
        #                 del metric[key]
        #
        #return kernel

    def _kernel_from_dict(self, kernel_dict):
        if type(kernel_dict) is list:
            return [Kern.from_dict(kd) for kd in kernel_dict]
        return Kern.from_dict(kernel_dict)

    def save_as_default_kernel(self):
        # TODO how to clip of tye Yvar portion
        if hasattr(self, '_kernel'):
            kernel_dict = self._kernel.to_dict()
        elif hasattr(self, '_kernels'):
            kernel_dict = [_k.to_dict() for _k in self._kernels]
        else:
            raise AssertionError("No emulator loaded, cannot save.")

        f = h5py.File(self.filename)
        f.attrs['kernel'] = kernel_dict
        f.close()
        #with open(DEFAULT_METRIC_PICKLE_FNAME, 'r') as f:
        #    default_kernel_dict = pickle.load(f)

        #default_kernel_dict[self.obs]= kernel_dict

        #with open(DEFAULT_METRIC_PICKLE_FNAME, 'w') as f:
        #    pickle.dump(default_kernel_dict, f)

    def _make_kernel(self, hyperparams):
        """
        Helper method to build a george kernel for GP's and kernel-based regressions.
        :param metric:
            Hyperparams for kernel determining relative length scales and amplitudes. Default is empty dict.
            In that case, the initial guesses from the object will be used.
        :return:
            A george ExpSquredKernel object with this metric
        """

        # I'm gonna try having the user build a kernel and pass it in, else defaults passed to default kenrel
        # lots of ways to take this but i'm just not feeling most of them
        if 'kernel' in hyperparams and type(hyperparams['kernel']) not in  (dict, list):
            return hyperparams['kernel']
        #elif 'kernel_name' in hyperparams:
            # TODO implement this with a dict
            # or not, not sure if its worth supporting
        elif 'kernel' in hyperparams: # is a dict from GPy
            return self._kernel_from_dict(hyperparams['kernel'])
        else:
            return self._get_default_kernel()

    ###Emulation and methods that Utilize it############################################################################
    def emulate(self, em_params, gp_errs=False):
        """
        Perform predictions with the emulator.
        :param em_params:
            Dictionary of what values to predict at for each param. Values can be
            an array or a float.
        :param gp_errs:
            Boolean, decide whether or not to return the errors from the gp prediction. Default is False.
            Will throw error if method is not gp.
        :return: mu, (errs)
                  The predicted value and the uncertainties for the predictions
                  mu and errs both have shape (npoints,)
        """

        # only has meaning for gp's
        assert not gp_errs or self.method == 'gp'

        input_params = {}
        # input_params.update(self.fixed_params)
        input_params.update(em_params)

        self._check_params(input_params)

        # create the dependent variable matrix
        t_list = [input_params[pname] for pname in self._ordered_params if pname in em_params]
        # cover spicy_buffalo edge case
        t_dim = self.emulator_ndim
# TODO this does a lot of extra uncecessary work for NH
        if hasattr(self, 'r_idx') and 'r' in input_params:
            t_list.insert(self.r_idx, input_params['r'])
            t_dim+=1

        t_grid = np.meshgrid(*t_list)
        t = np.stack(t_grid).T
        t = t.reshape((-1, t_dim))

        # TODO george can sort?
        _t = self._sort_params(t)
        if _t.shape == t.shape:  # protect against weird edge case...
            t = _t

        if len(t.shape) == 1:
            t = np.array([t])

        # whiten, but only non- Spicy Buffalo versions
        # I'm not psyched about this, but handling it in _emulator_helper is just easier
        # I need to know what rows corredspond to what rs for later
        # TODO standardize this
        #if hasattr(self, 'r_idx'):
        t, old_idxs = self._whiten(t)

        return self._emulate_helper(t, gp_errs, old_idxs = old_idxs)

    @abstractmethod
    def _emulate_helper(self, t, gp_errs=False, old_idxs = None):
        pass

    def emulate_wrt_r(self, em_params, r_bin_centers=None, gp_errs=False):
        """
        Helper function to emulate over r bins.
        :param em_params:
            Parameters to predict at
        :param r_bin_centers:
            Radial bins to predict at
        :param gp_err:
            Boolean, whether or not to use the errors from the GP. Default is False.
            If method is not 'gp', will throw an error
        :return: mu, (errs)
                mu has shape (n_points, len(r_bin_centers))
                errs, if returned, has the same shape
        """
        # TODO this should have scale bin centers as teh default, duh!
        if r_bin_centers is None:
            r_bin_centers = self.scale_bin_centers
        ep = {}
        ep.update(em_params)
        # extract z from the emulator params, if it's there
        # we will use this to call emulate_wrt_r_z below
        z_bin_centers = np.array([])
        if 'z' in ep:
            z_bin_centers = ep['z']
            if type(z_bin_centers) is float:
                z_bin_centers = np.array([z_bin_centers])
            del ep['z']
        elif 'z' not in self.fixed_params:
            raise ValueError("Please specify z in emulate_wrt_z")
        out = self.emulate_wrt_r_z(ep, r_bin_centers, z_bin_centers, gp_errs)

        # Extract depending on if there are errors
        if gp_errs:
            _mu, _errs = out
        else:
            _mu = out

        # now, reshape to have shape (-1, len(r_bin_centers))
        mu = _mu.reshape((-1, r_bin_centers.shape[0]))
        if not gp_errs:
            return mu

        errs = _errs.reshape(mu.shape)
        return mu, errs

    def emulate_wrt_z(self, em_params, z_bin_centers, gp_errs=False):
        """
        Helper function to emulate over z bins.
        :param em_params:
            Parameters to predict at
        :param z_bin_centers:
            Redshift bins to predict at
        :param gp_err:
            Boolean, whether or not to use the errors from the GP. Default is False.
            If method is not 'gp', will throw an error
        :return:mu, (errs)
                mu has shape (n_points, len(z_bin_centers))
                errs, if returned, has the same shape
        """
        ep = {}
        ep.update(em_params)
        r_bin_centers = np.array([])
        if 'r' in ep:
            r_bin_centers = ep['r']
            if type(r_bin_centers) is float:
                r_bin_centers = np.array([r_bin_centers])
            del ep['r']

        out = self.emulate_wrt_r_z(ep, r_bin_centers, z_bin_centers, gp_errs)
        # extract errors if they're returned
        if gp_errs:
            _mu, _errs = out
        else:
            _mu = out

        # now, reshape to have shape (-1, len(z_bin_centers))
        # The swapaxes are necessary to make sure the reshape works properly
        mu = _mu.swapaxes(1, 2).reshape((-1, z_bin_centers.shape[0]))

        if not gp_errs:
            return mu
        errs = _errs.swapaxes(1, 2).reshape(mu.shape)
        return mu, errs

    def emulate_wrt_r_z(self, em_params, r_bin_centers, z_bin_centers, gp_errs=False):
        """
        Conveniance function. Add's 'r' and 'z' to the emulation automatically, as this is the
        most common use case.
        :param em_params:
            Dictionary of what values to predict at for each param. Values can be array
            or float.
        :param r_bin_centers:
            numpy array. Centers of scale bins to predict at, for each point in HOD-space.
            Note this function takes their real-space values, not log-space.
        :param z_bin_centers:
            numpy array. Centers of redshift bins to predict at, for each point in HOD-space
        :param gp_errs:
            Wheter to return the errors of the Gaussian process or not.
        :return: mu, errs (if gp_errs == True)
                both have been reshaped to have shape (-1, len(z_bin_centers), len(r_bin_centers))
        """
        vep = dict(em_params)
        # take the log of r_bin_centers
        rpc = np.log10(r_bin_centers) if np.any(r_bin_centers) else np.array([])  # make sure not to throw an error

        # now, put them into the emulation dictionary.
        for key, val in izip(['r', 'z'], (rpc, z_bin_centers)):
            if key not in self.fixed_params and val.size:  # not fixed and the array is nonzero
                if key not in vep:
                    vep[key] = val
                else:
                    raise ValueError("The parameter %s has been specified twice in emulate_wrt_r_z!" % key)

        # now, emulate.
        out = self.emulate(vep, gp_errs)
        if gp_errs:
            _mu, _errs = out
        else:
            _mu = out

        # account for weird binning isues.
        if not z_bin_centers.shape[0]:
            if not r_bin_centers.shape[0]:
                mu = _mu.reshape((-1, 1, 1))
            else:
                mu = _mu.reshape((-1, 1, r_bin_centers.shape[0]))
        elif not r_bin_centers.shape[0]:
            mu = _mu.reshape((-1, z_bin_centers.shape[0], 1))
        else:
            mu = _mu.reshape((-1, z_bin_centers.shape[0], r_bin_centers.shape[0]))

        if not gp_errs:
            return mu
        errs = _errs.reshape(mu.shape)
        return mu, errs

    # TODO Jeremey keeps konwn uncertainties, I should do the same here, or near to here.
    def estimate_uncertainty(self, truth_dir, N=None):
        """
        Estimate the uncertainty of the emulator by comparing to a "test" box of true values.
        :param truth_dir:
            Name of a directory of true test values, of the same format as the train_dir
        :param N:
            Number of points to compare to. If None (default) will use all points. Else will select random sample.
        :return:
            covariance matrix with dim n_binsxn_bins. Will only have diagonal elemtns of est. uncertainties.
        """
        rms_err = self.goodness_of_fit(truth_dir, N, statistic='rms')

        return np.diag(rms_err ** 2)

    # only predicts wrt r. don't know if that's an ihmssue.
    # TODO change N to downsample_factor, overlap those two features
    def goodness_of_fit(self, truth_file, N=None, statistic='r2'):
        """
        Calculate the goodness of fit of an emulator as compared to some validation data.
        :param truth_dir:
            Directory structured similarly to the training data, but NOT used for training.
        :param N:
            Number of points to use to calculate G.O.F. measures. "None" tests against all values in truth_dir. If N
            is less than the number of points, N are randomly selected. Default is None.
        :param statistic:
            What G.O.F. statistic to calculate. Default is r2. Other options are rmsfd, abs(olute), and rel(ative).
        :return: values, a numpy arrray of the calculated statistics at each of the N training points.
        """
        assert statistic in {'r2', 'rms', 'rmsfd', 'abs', 'log_abs', 'frac', 'log_frac', None}
        if N is not None:
            assert N > 0 and int(N) == N

        x, y, _, info = self.get_data(truth_file, self.fixed_params)

        x, old_idxs  = self._whiten(x)
        #y = (y - self._y_mean)/(self._y_std + 1e-5)

        scale_bin_centers = info['sbc']
        scale_nbins = len(scale_bin_centers) if 'r' not in self.fixed_params else 1

        np.random.seed(int(time()))

        # TODO this is busted
        # Replace with downsample
        if N is not None:  # make a random choice
            if hasattr(self, 'r_idx'):
                _x, _y = [], []
                _old_idxs = []
                 
                idxs = sorted(np.random.choice(old_idxs[0].shape[0], N*self.n_bins, replace = False))
                for i in xrange(self.n_bins):

                    in_bin_idxs = old_idxs[i][idxs]
                    _old_idxs.append(in_bin_idxs)

                    #sub_idxs = np.zeros((x[i].shape[0],), dtype = bool)
                    sub_idxs = np.isin(np.where(old_idxs[i])[0], idxs, assume_unique = True)
                    _x.append(x[i][sub_idxs])
                    _y.extend(y[old_idxs[i]][sub_idxs])
                    #_old_idxs[i] = old_idxs[i][idxs]

                x, y = _x, np.array(_y)
                old_idxs = _old_idxs
            else:
                idxs = np.random.choice(y.shape[0], N*scale_nbins, replace=False)

                x, y = x[idxs], y[idxs]
        
        pred_y = self._emulate_helper(x, False)[:,0]#, old_idxs = old_idxs)

        #if scale_nbins > 1:
        #    try:
        #        y = y.reshape((-1, scale_nbins))
        #        pred_y = pred_y.reshape((-1, scale_nbins))
        #    except ValueError: #Can't reshpae, ahwell
        #        pass

        # TODO untested

        if np.any(scale_bin_centers != self.scale_bin_centers):
            bin_centers = scale_bin_centers[self.scale_bin_centers[0] <= scale_bin_centers <= self.scale_bin_centers[-1]]
            new_mu = []
            for mean in pred_y:
                xi_interpolator = interp1d(self.scale_bin_centers, mean, kind='slinear')
                interp_mean = xi_interpolator(bin_centers)
                new_mu.append(interp_mean)
            pred_y = np.array(new_mu)
            y = y[:, self.scale_bin_centers[0] <= bin_centers <= self.scale_bin_centers[-1]]

        if statistic is None:
            if hasattr(self, 'r_idx'): #resshape
                pred_out, out  = [], []
                for i in xrange(self.n_bins):
                    pred_out.append(pred_y[old_idxs[i]])
                    out.append(y[old_idxs[i]])

                return pred_out, out
            else:
                return pred_y, y

        elif statistic == 'rmsfd':
            return np.sqrt(np.mean((((pred_y - y) ** 2) / (y ** 2)), axis=0))

        elif statistic == 'rms':
            return np.sqrt(np.mean(((pred_y - y) ** 2), axis=0))

        # TODO sklearn methods can do this themselves. But i've already tone the prediction!
        elif statistic == 'r2':  # r2
            SSR = np.sum((pred_y - y) ** 2, axis=0)
            SST = np.sum((y - y.mean(axis=0)) ** 2, axis=0)

            return 1 - SSR / SST

        elif statistic == 'abs':
            return 10 ** pred_y - 10 ** y
            # return np.mean(10 ** pred_y - 10 ** y, axis = 0)
        elif statistic == 'log_abs':
            return pred_y - y
            # return np.mean((pred_y - y), axis=0)
        elif statistic == 'log_frac':  # 'rel'
            out = np.abs(pred_y - y) / np.abs(y)
            if hasattr(self, 'r_idx'): #resshape
                _out = []
                for i in xrange(self.n_bins):
                    _out.append(out[old_idxs[i]])
                out = _out
            return out 
            # return np.mean((pred_y - y) / y, axis=0)
        else:  # 'frac'
            out = np.abs(10**pred_y - 10**y) / np.abs(10**y)
            if hasattr(self, 'r_idx'): #resshape
                _out = []
                for i in xrange(self.n_bins):
                    _out.append(out[old_idxs[i]])
                out = _out
            return out 

    @abstractmethod
    def _emulator_lnlikelihood(self):
        pass

    @abstractmethod
    def train_metric(self):#,p0, **kwargs):
        pass


    # TODO this feature is not super useful anymore, and also is poorly defined w.r.t non gp methods.
    # did a lot of work on it tho, maybe i'll leave it around...?
    # TODO this feature is no longer correct with EC
    def _loo_errors(self, y, t):
        """
        Calculate the LOO Jackknife error matrix. This is implemented using the analytic LOO procedure,
        which is much faster than re-doing an inversion for each sample. May be useful if the GP's matrix is not
        accurate.
        :param y:
            Values of the independent variable for the training points, used in the prediction.
        :param t:
            Values of the dependant variables to predict at.
        :return:
            jk_cov: a covariance matrix with the dimensions of cov.
        """
        # from time import time

        assert self.method == 'gp'

        if isinstance(self, ExtraCrispy):
            emulator = self._emulators[0]  # hack for EC, do somethign smarter later
        else:
            emulator = self._emulator

        # We need to perform one full inverse to start.
        K_inv_full = emulator.solver.apply_inverse(np.eye(emulator._alpha.size),
                                                   in_place=True)

        # TODO deepcopy?
        x = self.x[:]

        N = K_inv_full.shape[0]

        mus = np.zeros((N, t.shape[0]))
        # t0 = time()

        # iterate over training points to leave out
        for idx in xrange(N):
            # swap the values of the LOO point and the last point.
            x[[N - 1, idx]] = x[[idx, N - 1]]
            y[[N - 1, idx]] = y[[idx, N - 1]]

            K_inv_full[[idx, N - 1], :] = K_inv_full[[N - 1, idx], :]
            K_inv_full[:, [idx, N - 1]] = K_inv_full[:, [N - 1, idx]]

            # the inverse of the LOO GP
            # formula found via MATH
            K_m_idx_inv = K_inv_full[:N - 1, :][:, :N - 1] \
                          - np.outer(K_inv_full[N - 1, :N - 1], K_inv_full[:N - 1, N - 1]) / K_inv_full[N - 1, N - 1]

            alpha_m_idx = np.dot(K_m_idx_inv, y[:N - 1] - emulator.mean(x[:N - 1]))

            Kxxs_t = emulator.kernel.value(t, x[:N - 1])

            # Store the estimate for this LOO GP
            mus[idx, :] = np.dot(Kxxs_t, alpha_m_idx) + emulator.mean(t)

            # restore the original values for the next loop
            x[[N - 1, idx]] = x[[idx, N - 1]]
            y[[N - 1, idx]] = y[[idx, N - 1]]

            K_inv_full[[idx, N - 1], :] = K_inv_full[[N - 1, idx], :]
            K_inv_full[:, [idx, N - 1]] = K_inv_full[:, [N - 1, idx]]

        # return the jackknife cov matrix.
        cov = (N - 1.0) / N * np.cov(mus, rowvar=False)
        if mus.shape[1] == 1:
            return np.array([[cov]])  # returns float in this case
        else:
            return cov


class OriginalRecipe(Emu):
    """Emulator that emulates with only one learner that is trained on all training data. The "naive" approach. """

    def _downsample_data(self, downsample_factor, x, y, yerr, attach=False):

        N_points = x.shape[0]/self.n_bins #sample full HOD/cosmo points,
        downsample_N_points = int(downsample_factor*N_points)
        downsample_x = np.zeros((downsample_N_points*self.n_bins, x.shape[1]))
        downsample_y = np.zeros((downsample_N_points*self.n_bins,1))
        downsample_yerr = np.zeros((downsample_N_points*self.n_bins,1))

        downsampled_points = np.random.choice(N_points, downsample_N_points, replace = False)

        for i, dp in enumerate(downsampled_points):
            downsample_x[i*self.n_bins:(i+1)*self.n_bins] = x[dp*self.n_bins: (dp+1)*self.n_bins]
            downsample_y[i*self.n_bins:(i+1)*self.n_bins] = y[dp*self.n_bins: (dp+1)*self.n_bins]
            downsample_yerr[i*self.n_bins:(i+1)*self.n_bins] = yerr[dp*self.n_bins: (dp+1)*self.n_bins]

        if attach:
            self.downsample_x = downsample_x
            self.downsample_y = downsample_y
            self.downsample_yerr = downsample_yerr
        else:
            return downsample_x, downsample_y, downsample_yerr

    def _build_gp(self, hyperparams):
        """
        Initialize the GP emulator.
        :param hyperparams:
            Key word parameters for the emulator
        :return: None
        """
        # TODO could use more of the hyperparams...
        kernel = self._make_kernel(hyperparams)

        if self._downsample_factor == 1.0:
            x, y, yerr  = self.x, self.y, self.yerr
        else:
            x, y, yerr  = self.downsample_x, self.downsample_y, self.downsample_yerr

        noise = Fixed(kernel.input_dim, np.diag(yerr[:, 0]**2))
        self._emulator = GPRegression(x, y, kernel)#+noise)
        self._kernel = kernel

    def _build_skl(self, hyperparams):
        """
        Build a scikit learn emulator
        :param hyperparams:
            Key word parameters for the emulator
        :return: None
        """

        if self.method in {'svr', 'krr'}:  # kernel based method
            metric = hyperparams['metric'] if 'metric' in hyperparams else {}
            kernel = self._make_kernel(metric)
            if 'metric' in hyperparams:
                del hyperparams['metric']
            # slight difference in use for these saldy
            if self.method == 'svr':
                hyperparams['kernel'] = kernel.value
            else:  # krr
                hyperparams['kernel'] = lambda x1, x2: kernel.value(np.array([x1]), np.array([x2]))

        self._emulator = self.skl_methods[self.method](**hyperparams)

        if self._downsample_factor == 1.0:
            x, y = self.x, self.y
        else:
            x, y = self.downsample_x, self.downsample_y

        self._emulator.fit(x, y)

    def _emulate_helper(self, t, gp_errs):
        """
        Helper function that takes a dependent variable matrix and makes a prediction.
        :param t:
            Dependent variable matrix. Assumed to be in the order defined by ordered_params
        :param gp_errs:
            Whether or not to return errors in the gp case
        :return:
            mu, err (if gp_errs True). Predicted value for dependetn variable t.
            mu and err both have shape (t.shape[0])
        """

        mean_func_at_params = self.mean_function(t)

        if self.method == 'gp':
            mu, vars = self._emulator.predict(t, kern = self._kernel.copy())
            if gp_errs:
                return self._y_std*(mu+mean_func_at_params)+self._y_mean, vars*self._y_std**2
            return self._y_std*(mu+mean_func_at_params)+self._y_mean
        else:
            mu = self._emulator.predict(t)
            return self._y_std*(mu+mean_func_at_params) + self._y_mean

    def _emulator_lnlikelihood(self):
        """

        """
        # TODO docs
        assert self.method == 'gp', "Lnliklihood only valid for GP emulators. "

        return self._emulator.log_likelihood(), self._emulator.log_likelihood_gradient()


    def train_metric(self):#,p0=None, **kwargs):
        """
        Train the metric parameters of the GP. Has a spotty record of working.
        Best used as used in lowDimTraining.
        If attempted to be used with an emulator that is not GP, will raise an error.
        :param kwargs:
            Kwargs that will be passed into the scipy.optimize.minimize
        :return: success: True if the training was successful.
        """

        # TODO kernel based methods may want to use this...
        # TODO may wanna make some of these hyperparams
        assert self.method == 'gp'
        self._emulator.optimize_restarts(num_restarts = 3, verbose = True)


def get_leaves(kdtree):
    """
    Helper function for recursively retriving the leaves of a KDTree
    :param: kdtree
        instance of KDTree to recover leaves of.
    :return: leaves, a list of  numpy arrays of shape (experts, points_per_expert), of leaves.
    """
    #points_per_expert = kdtree.leafsize
    leaves_list = []
    get_leaves_helper(kdtree.tree, leaves_list)

    return [np.array(l) for l in leaves_list]


def get_leaves_helper(node, leaves):
    """
    Meta helper function. Recursively
    """
    if isinstance(node, KDTree.leafnode):
        leaves.append(node.idx)
    else:
        get_leaves_helper(node.less, leaves)
        get_leaves_helper(node.greater, leaves)

# Considering depreceating this since it is no longer useful
class ExtraCrispy(Emu):
    """Emulator that emulates with a mixture of expert learners rather than a single one."""

    def __init__(self, filename, experts, overlap=1, partition_scheme='random', **kwargs):
        """
        Similar initialization as the superclass with one additional parameter: Em_param
        :param training_dir:
            See above in EMu
        :param experts:
            number of experts to use in the mixture. Must be an integer greater than 1.
        :param overlap:
            overlap in training points between experts. For example, if overlap=2, each datapoint will be in
            2 experts. Default is 1, no overlap.
        :param kwargs:
            As in Emu
        """

        assert experts > 1 and int(experts) == experts  # no point in having less than this
        # TODO experts max value?
        # no point in having overlap the same as experts. You just have experts-many identical gps!
        assert experts > overlap > 0 and int(overlap) == overlap
        assert partition_scheme in {'kdtree', 'random'}

        self.experts = int(experts)
        self.overlap = int(overlap)
        self.partition_scheme = partition_scheme

        super(ExtraCrispy, self).__init__(filename, **kwargs)

    def load_training_data(self, filename, custom_mean_function = None):
        """
        Read the training data for the emulator and attach it to the object.
        :param training_dir:
            Directory where training data from trainginData is stored.
        :param fixed_params:
            Parameters to hold fixed. Only available if data in training_dir is a full hypercube, not a latin hypercube.
        :return: None
        """
        super(ExtraCrispy, self).load_training_data(filename, custom_mean_function)

        # now, parition the data as specified by the user
        # note that ppe does not include overlap
        points_per_expert = int(1.0 * self.x.shape[0] * self.overlap / self.experts)

        try:
            assert points_per_expert > 0
        except AssertionError:
            raise AssertionError("You have too many experts!")

        _x = np.zeros((self.experts, points_per_expert, self.x.shape[1]))
        _y = np.zeros((self.experts, points_per_expert))
        _yerr = np.zeros_like(_y)

        if self.partition_scheme == 'random':
            shuffled_idxs = range(self.y.shape[0])
            np.random.shuffle(shuffled_idxs)

            # select potentially self.overlapping subets of the data for each expert
            for i in xrange(self.experts):
                _x[i, :, :] = np.roll(self.x[shuffled_idxs, :], i * points_per_expert / self.overlap, 0)[
                              :points_per_expert, :]
                _y[i, :] = np.roll(self.y[shuffled_idxs], i * points_per_expert / self.overlap, 0)[:points_per_expert]

                _yerr[i, :] = np.roll(self.yerr[shuffled_idxs], i * points_per_expert / self.overlap, 0)[
                              :points_per_expert]

        else:  # KDTree
            # whiten so all distances are the same
            normed_x = (self.x - self.x.min(axis=0)) / self.x.max(axis=0)
            normed_x[np.isnan(normed_x)] = 0.0
            kdtree = KDTree(normed_x, leafsize=points_per_expert / self.overlap)
            leaves = get_leaves(kdtree)

            prev_idx, curr_idx = 0, 0
            # If points cannot be evenly divided, there'll be some skipped ones.
            # We'll add them in at the end.
            n_missed = np.sum([(self.overlap * len(leaf) % self.experts) / self.overlap for leaf in leaves])

            missed_points = np.zeros(n_missed, dtype=int)
            missed_idx = 0

            # leaves can have different sizes, so we have to treat each leaf differently
            for i, leaf in enumerate(leaves):
                shuffled_idxs = range(leaf.shape[0])
                np.random.shuffle(shuffled_idxs)

                leaf_ppe = int(1.0 * self.overlap * leaf.shape[0] / self.experts)
                curr_idx = prev_idx + leaf_ppe

                # select potentially overlapping subets of the data for each expert
                for j in xrange(self.experts):
                    _x[j, prev_idx:curr_idx, :] = \
                        np.roll(self.x[leaf[shuffled_idxs], :], j * leaf_ppe / self.overlap, 0)[:leaf_ppe, :]
                    _y[j, prev_idx:curr_idx] = \
                        np.roll(self.y[leaf[shuffled_idxs]], j * leaf_ppe / self.overlap, 0)[:leaf_ppe]
                    _yerr[j, prev_idx:curr_idx] \
                        = np.roll(self.yerr[leaf[shuffled_idxs]], j * leaf_ppe / self.overlap, 0)[:leaf_ppe]

                prev_idx = curr_idx
                nm = (self.overlap * leaf.shape[0] % self.experts) / self.overlap
                if nm != 0:
                    missed_points[missed_idx:missed_idx + nm] = leaf[shuffled_idxs][-nm:]
                    missed_idx += nm

            # now, distribute leftover points over experts
            if n_missed > 0:
                missed_ppe = int(1.0 * n_missed * self.overlap / self.experts)

                curr_idx = prev_idx + missed_ppe

                for i in xrange(self.experts):
                    _x[i, prev_idx:curr_idx, :] = \
                        np.roll(self.x[missed_points, :], i * missed_ppe / self.overlap, 0)[:missed_ppe, :]
                    _y[j, prev_idx:curr_idx] = \
                        np.roll(self.y[missed_points], i * missed_ppe / self.overlap, 0)[:missed_ppe]
                    _yerr[j, prev_idx:curr_idx] \
                        = np.roll(self.yerr[missed_points], i * missed_ppe / self.overlap, 0)[:missed_ppe]

                # now, to cover the meta-missed ones, just fill in points until they're full
                while curr_idx != self.x.shape[1]:
                    prev_idx = curr_idx
                    curr_idx += 1
                    for j in xrange(self.experts):
                        _x[j, prev_idx:curr_idx, :] = \
                            np.roll(self.x[missed_points, :], (j + i) * missed_ppe / self.overlap, 0)[:1, :]
                        _y[j, prev_idx:curr_idx] = \
                            np.roll(self.y[missed_points], (j + i) * missed_ppe / self.overlap, 0)[:1]
                        _yerr[j, prev_idx:curr_idx] \
                            = np.roll(self.yerr[missed_points], (j + i) * missed_ppe / self.overlap, 0)[:1]

        # now attach these final versions
        self.x = _x
        self.y = _y

    def _downsample_data(self, downsample_factor, x, y, yerr, attach=False):

        N_points = x.shape[1]  # don't sample full HOD/cosmo points. Already broken up in experts
        downsample_N_points = int(downsample_factor * N_points)
        downsample_x = np.zeros((x.shape[0], downsample_N_points, x.shape[2]))
        downsample_y = np.zeros((y.shape[0], downsample_N_points))
        downsample_yerr = np.zeros((y.shape[0], downsample_N_points))

        for e in xrange(self.experts):

            downsampled_points = np.random.choice(N_points, downsample_N_points, replace=False)

            for i, dp in enumerate(downsampled_points):
                downsample_x[e,i :(i + 1)] = x[e,dp : (dp + 1)]
                downsample_y[e,i :(i + 1) ] = y[e,dp: (dp + 1)]
                downsample_yerr[e,i:(i + 1)] = yerr[e,dp: (dp + 1)]

        if attach:
            self.downsample_x = downsample_x
            self.downsample_y = downsample_y
            self.downsample_yerr = downsample_yerr
        else:
            return downsample_x, downsample_y, downsample_yerr

    def _build_gp(self, hyperparams):
        """
        Initialize the GP emulator using an MOE model.
        :param hyperparams:
            Key word parameters for the emulator
        :return: None
        """
        # note may have to return a few unique kernels..
        kernel = self._make_kernel(hyperparams)

        if type(kernel) is not list:
            kernel = [kernel for i in xrange(self.n_bins)]

        # now, make a list of emulators
        self._emulators = []
        self._kernels = []

        if self._downsample_factor == 1.0:
            x = self.x
            y = self.y
            yerr = self.yerr
            # Yerr taken care of in kernel
        else:
            x = self.downsample_x
            y = self.downsample_y
            yerr = self.downsample_yerr

        for _x, _y,_yerr,  k in izip(x, y, yerr, kernel):
            noise = Fixed(k.input_dim, covariance_matrix=np.diag(_yerr))
            emulator = GPRegression(_x, _y, k+noise)
            self._emulators.append(emulator)
            self._kernels.append(k)

    def _build_skl(self, hyperparams):
        """
        Build a scikit learn emulator using a mixtrue of experts.
        :param hyperparams:
            Key word parameters for the emulator
        :return: None
        """
        skl_methods = {'gbdt': GradientBoostingRegressor, 'rf': RandomForestRegressor, \
                       'svr': SVR, 'krr': KernelRidge}

        # Same kernel concerns as above.
        if self.method in {'svr', 'krr'}:  # kernel based method
            metric = hyperparams['metric'] if 'metric' in hyperparams else {}
            kernel = self._make_kernel(metric)
            if 'metric' in hyperparams:
                del hyperparams['metric']
            if self.method == 'svr':  # slight difference in these, sadly
                hyperparams['kernel'] = kernel.value
            else:  # krr
                hyperparams['kernel'] = lambda x1, x2: kernel.value(np.array([x1]), np.array([x2]))

        self._emulators = [self.skl_methods[self.method](**hyperparams) for i in xrange(self.experts)]

        if self._downsample_factor == 1.0:
            x = self.x
            y = self.y
        else:
            x = self.downsample_x
            y = self.downsample_y
        for i, (emulator, _x, _y) in enumerate(izip(self._emulators, x, y)):
            emulator.fit(_x, _y)

    def _emulate_helper(self, t, gp_errs=False, old_idxs = None):
        """
        Helper function that takes a dependent variable matrix and makes a prediction.
        :param t:
            Dependent variable matrix. Assumed to be in the order defined by ordered_params
        :param gp_errs:
            Whether or not to return errors in the gp case
        :return:
            mu, err (if gp_errs True). Predicted value for dependetn variable t.
            mu and err both have shape (npoints*self.redshift_bin_centers*self.scale_bin_centers)
        """
        mu = np.zeros((self.experts, t.shape[0]))  # experts down, t deep
        err = np.zeros_like(mu)

        mean_func_at_params = self.mean_function(t)

        for i, emulator in enumerate(self._emulators):
            if self.method == 'gp':
                local_mu, local_err = emulator.predict(t, self._kernels[i].copy())
                #local_mu = emulator.predict(_y, t, return_cov = False,return_var=False)
                #local_err = 1.0
            else:
                local_mu = emulator.predict(t)
                local_err = 1.0  # weight with this instead of the errors.

            mu[i, :] = self._y_std*(local_mu + mean_func_at_params) + self._y_mean
            err[i, :] = local_err*self._y_std


        # now, combine with weighted average
        combined_var = np.reciprocal(np.sum(np.reciprocal(err ** 2), axis=0))
        combined_mu = combined_var * np.sum(np.reciprocal(err ** 2) * mu, axis=0)

        # Reshape to be consistent with my other implementation
        if not gp_errs:
            return combined_mu

        return combined_mu, np.sqrt(combined_var)

    def _emulator_lnlikelihood(self):
        """
        """
        assert self.method == 'gp', "Lnlikelikihood only available for GP emulators."

        ll = 0
        gll = 0

        for idx, emulator in enumerate(self._emulators):
            ll += emulator.log_likelihood()
            gll += emulator.log_likelihood_gradient()

        # The scipy optimizer doesn't play well with infinities.

        ll = ll if np.isfinite(ll) else -1e25

        return ll, gll

    # TODO could make this learn the metric for other kernel based emulators...
    def train_metric(self):#, p0=None,  **kwargs):
        """
        Train the emulator. Has a spotty record of working. Better luck may be had with the NAMEME code.
        :param kwargs:
            Kwargs that will be passed into the scipy.optimize.minimize
        :return: success: True if the training was successful.
        """

        assert self.method == 'gp'

        # TODO should pmap this
        for emulator in self._emulators:
            emulator.optimize_restarts(num_restarts = 3, verbose = False)


class SpicyBuffalo(Emu):
    """Emulator that emulates with one emulator per scale bin rather than having it be a parameter.
       In practice this has better accuracy."""

    def load_training_data(self, filename, custom_mean_function=None):
        """
        Read the training data for the emulator and attach it to the object.
        :param training_dir:
            Directory where training data from trainginData is stored.
        :param fixed_params:
            Parameters to hold fixed. Only available if data in training_dir is a full hypercube, not a latin hypercube.
        :return: None
        """
        # make sure we attach metadata to the object
        x, y, ycov = self.get_data(filename, self.fixed_params, attach_params=True, remove_nans=True)

        # store the data loading args, if we wanna reload later
        # useful ofr sampling the training data

        y_std = 1.0  # y.mean(axis = 0), y.std(axis = 0)

        ycov_list = []
        for yc in ycov:
            ycov_list.append(yc / (np.outer(y_std, y_std) + 1e-5))

        ycov = ycov_list
        yerr = np.sqrt(np.hstack(np.diag(np.array(syc)) for syc in ycov))

        # in general, the full cov matrix will be too big, and we won't need it. store the diagonal, and
        # an average

        # compute the average covaraince matrix
        self.ycov = np.zeros((self.n_bins, self.n_bins))
        n_right_shape = 0
        # if len(ycov) == 1 and type(ycov) is not list:
        #    for yc in ycov.T:
        #        if yc.shape[0] != self.n_bins:
        #            continue
        #        elif np.any(np.isnan(yc)):
        #            continue
        #        n_right_shape+=1
        #        self.ycov+=yc
        for yc in ycov:
            if yc.shape[0] != self.n_bins:
                continue
            elif np.any(np.isnan(yc)):
                continue

            n_right_shape += 1
            self.ycov += yc

        self.ycov /= n_right_shape

        ndim = x.shape[1] - 1
        self.emulator_ndim = ndim  # The number of params for the emulator is different than those in sampling.

        # now, parition the data as specified by the user
        # note that ppe does not include overlap
        points_per_expert = int(1.0 * x.shape[0] / self.n_bins)

        try:
            assert points_per_expert > 0
        except AssertionError:
            raise AssertionError("You have too many scale bins!")

        # we have to have lists, since some may have been dropped due to Nans.
        # There's definetly a better way to do this ...
        self.x = []
        self.y = []
        self.yerr = []

        self._x_mean, self._x_std = [], []
        self._y_mean, self._y_std = np.zeros((self.n_bins,)), np.ones((self.n_bins,))  # [], []

        # TODO different hyperparams depending on what this is.

        r_idx = self.get_param_names().index('r')
        self.r_idx = r_idx  # we'll need this later, too
        del self._ordered_params['r']  # remove r!

        skip_r_idx = np.ones((x.shape[1]), dtype=bool)
        skip_r_idx[r_idx] = False

        for bin_no, sbc in enumerate(np.log10(self.scale_bin_centers)):
            bin_idxs = np.isclose(sbc, x[:, r_idx])

            x_in_bin = x[bin_idxs, :][:, skip_r_idx]
            x_mean, x_std = x_in_bin.mean(axis=0), x_in_bin.std(axis=0)

            if type(self._y_mean) is list:  # don't do the calculation if we've decided we don't whiten y
                y_mean, y_std = y[bin_idxs].mean(), y[bin_idxs].std()
            else:
                y_mean, y_std = self._y_mean[bin_no], self._y_std[bin_no]

            self.x.append((x_in_bin - x_mean) / (x_std + 1e-5))
            self.y.append((y[bin_idxs] - y_mean) / (y_std + 1e-5))
            self.yerr.append(yerr[bin_idxs])

            self._x_mean.append(x_mean)
            self._x_std.append(x_std)

            if type(self._y_mean) is list:
                self._y_mean.append(y_mean)
                self._y_std.append(y_std)


        self.mean_function = self._make_custom_mean_function(custom_mean_function)
        for i, mf in enumerate(self.mean_function(self.x)):
            self.y[i] -= mf

    def _whiten(self, x, arr = 'x'):
        """
        TODO
        :param x:
        :param arr:
        :return:
        """
        r_idx = self.r_idx
        skip_r_idx = np.ones(self.emulator_ndim+1, dtype = bool)
        skip_r_idx[r_idx] = False


        if type(x) is list and len(x) == self.n_bins:
            out = []
            if arr == 'x':
                for x_in_bin, x_mean, x_std in izip(x, self._x_mean, self._x_std):
                    out.append(((x_in_bin - x_mean)/(x_std + 1e-5) ) )
            elif arr == 'y':
                for x_in_bin, x_mean, x_std in izip(x, self._y_mean, self._y_std):
                    out.append(((x_in_bin - x_mean)/(x_std + 1e-5) ) )
            else:
                raise NotImplementedError
            out = np.array(out)
            return out, None

        elif x.shape[1] == self.emulator_ndim+1: #has an r axies
            assert arr == 'x'

            # Note, reshape so there are n_bins lists, with each in corresponding to the bin
            # will enable me to iterate over it, and make all preds at the same time
            out = []
            all_bin_idxs = []
            for bin_no, sbc in enumerate(np.log10(self.scale_bin_centers)):
                bin_idxs = np.isclose(sbc, x[:, r_idx])
                val = (x[bin_idxs, :][:, skip_r_idx] - self._x_mean[bin_no])/(self._x_std[bin_no]+1e-5)
                if type(val) is float:
                    val = np.array([val])

                out.append(val)
                all_bin_idxs.append(bin_idxs)
            return out, all_bin_idxs
        else:
            raise NotImplementedError

    def _make_custom_mean_function(self, custom_mean_function =None):
        """
        Generate a custom mean function to make training better behaved (in theory)
        """
        # TODO docs

        if custom_mean_function is None:
            return lambda x: np.zeros((self.n_bins,)) 

        elif custom_mean_function == 'linear' or custom_mean_function == 1:
            self._mean_func = [LinearRegression() for i in xrange(self.n_bins)]#TODO hyperparams
            for i, mf in enumerate(self._mean_func):
                mf.fit(self.x[i], self.y[i])

            return lambda x: np.array([mf.predict(_x) for _x, mf  in izip(x, self._mean_func)])

        elif type(custom_mean_function) is int and custom_mean_function > 0: # TODO would like to take a dict here maybe, for kwargs
            self._mean_func = [make_pipeline(PolynomialFeatures(custom_mean_function), LinearRegression()) for i in xrange(self.n_bins)]
            for i, mf in enumerate(self._mean_func):
                mf.fit(self.x[i], self.y[i])

            return lambda x: np.array([mf.predict(_x) for _x, mf  in izip(x, self._mean_func)])

        else:
            raise NotImplementedError #TODO add something better! 

    def check_param_names(self, param_names, ignore=[]):
        #see above, just adding 'r' to ignore by default
        ig = ['r'] if 'r' not in ignore else []
        ig.extend(ignore)
        return super(SpicyBuffalo, self).check_param_names(param_names, ig)

    def _downsample_data(self, downsample_factor, x, y, yerr, attach=False):

        N_points = max([_x.shape[0] for _x in x]) # don't sample full HOD/cosmo points. Already broken up in experts
        downsample_N_points = int(downsample_factor * N_points)
        downsample_x = [np.zeros((downsample_N_points, x[0].shape[1] )) for i in xrange(self.n_bins)]
        downsample_y = [np.zeros((downsample_N_points, )) for i in xrange(self.n_bins)]
        downsample_yerr = [ np.zeros((downsample_N_points, )) for i in xrange(self.n_bins)]

        for e in xrange(self.n_bins):

            downsampled_points = np.random.choice(len(x[e]), downsample_N_points, replace=False)

            for i, dp in enumerate(downsampled_points):
                downsample_x[e][i :(i + 1)] = x[e][dp : (dp + 1)]
                downsample_y[e][i :(i + 1) ] = y[e][dp: (dp + 1)]
                downsample_yerr[e][i:(i + 1)] = yerr[e][dp: (dp + 1)]

        if attach:
            self.downsample_x = downsample_x
            self.downsample_y = downsample_y
            self.downsample_yerr = downsample_yerr
        else:
            return downsample_x, downsample_y, downsample_yerr

    def _build_gp(self, hyperparams):
        """
        Initialize the GP emulator using an MOE model.
        :param hyperparams:
            Key word parameters for the emulator
        :return: None
        """
        kernel = self._make_kernel(hyperparams)

        if type(kernel) is not list:
            kernel = [kernel for i in xrange(self.n_bins)]

        # now, make a list of emulators
        self._emulators = []
        self._kernels = []

        # yerr taken care of in kernel
        if self._downsample_factor == 1.0:
            x = self.x
            y = self.y
            yerr = self.yerr
        else:
            x = self.downsample_x
            y= self.downsample_y
            yerr = self.downsample_yerr

        for _x, _y,_yerr, _kernel in izip(x, y,yerr, kernel):
            noise = Fixed(_kernel.input_dim, covariance_matrix=np.diag(_yerr))
            emulator = GPRegression(_x,_y, _kernel+noise)
            self._emulators.append(emulator)
            self._kernels.append(_kernel)

    def _build_skl(self, hyperparams):
        """
        Build a scikit learn emulator using a mixtrue of experts.
        :param hyperparams:
            Key word parameters for the emulator
        :return: None
        """
        skl_methods = {'gbdt': GradientBoostingRegressor, 'rf': RandomForestRegressor, \
                       'svr': SVR, 'krr': KernelRidge}

        # Same kernel concerns as above.
        if self.method in {'svr', 'krr'}:  # kernel based method
            metric = hyperparams['metric'] if 'metric' in hyperparams else {}
            kernel = self._make_kernel(metric)
            if 'metric' in hyperparams:
                del hyperparams['metric']
            if self.method == 'svr':  # slight difference in these, sadly
                hyperparams['kernel'] = kernel.value
            else:  # krr
                hyperparams['kernel'] = lambda x1, x2: kernel.value(np.array([x1]), np.array([x2]))

        self._emulators = [self.skl_methods[self.method](**hyperparams) for i in xrange(self.n_bins)]

        if self._downsample_factor == 1.0:
            x = self.x
            y = self.y
        else:
            x = self.downsample_x
            y = self.downsample_y
        for i, (emulator, _x, _y) in enumerate(izip(self._emulators, x, y)):
            emulator.fit(_x, _y)

    def _emulate_helper(self, t, gp_errs=False, old_idxs = None):
        """
        Helper function that takes a dependent variable matrix and makes a prediction.
        :param t:
            Dependent variable matrix. Assumed to be in the order defined by ordered_params
        :param gp_errs:
            Whether or not to return errors in the gp case
        :return:
            mu, err (if gp_errs True). Predicted value for dependetn variable t.
            mu and err both have shape (npoints*self.redshift_bin_centers*self.scale_bin_centers)
        """
        #
        t_size = np.sum([_t.shape[0] for _t in t])

        mean_func_at_params = self.mean_function(t)

        mu = []
        err = []

        for bin_no, (t_in_bin, mfc, emulator) in enumerate(izip(t, mean_func_at_params, self._emulators)):

            if self.method == 'gp':
                if gp_errs:
                    local_mu, local_err = emulator.predict(t_in_bin, kern = self._kernels[bin_no].copy())
                else:
                    #print _y
                    #print t_in_bin
                    local_mu, _ = emulator.predict(t_in_bin, kern = self_kernels[bin_no].copy())
                    #print local_mu
                    local_err = np.ones_like(local_mu)

            else:
                local_mu = emulator.predict(t_in_bin)
                local_err = np.ones_like(local_mu)  # weight with this instead of the errors.

            #print 'local_mu, mfc', local_mu, mfc
            mu.append(self._y_std[bin_no]*(local_mu + mfc) + self._y_mean[bin_no])
            err.append(local_err*self._y_std[bin_no])

        #now, figure out how to return to the shape of t
        combined_mu = np.zeros((t_size,))
        combined_err = np.zeros((t_size,))

        for r_idx, bin_idxs in enumerate(old_idxs):
            combined_mu[bin_idxs] =  mu[r_idx]
            combined_err[bin_idxs] =  err[r_idx]

        # Reshape to be consistent with my other implementation
        if not gp_errs:
            return combined_mu

        return combined_mu, combined_err

    def _emulator_lnlikelihood(self):
        """
        """
        assert self.method == 'gp'

        # TODO figure out gradient as well
        ll = 0
        gll = 0

        for idx, emulator in enumerate(self._emulators ):
            ll += emulator.log_likelihood()#
            gll += emulator.log_likelihood_grad()

        # The scipy optimizer doesn't play well with infinities.

        ll = ll if np.isfinite(ll) else -1e25

        return ll, gll

    # TODO could make this learn the metric for other kernel based emulators...
    def train_metric(self, p0=None,  **kwargs):
        """
        Train the emulator. Has a spotty record of working. Better luck may be had with the NAMEME code.
        :param kwargs:
            Kwargs that will be passed into the scipy.optimize.minimize
        :return: success: True if the training was successful.
        """

        assert self.method == 'gp'

        for emulator in self._emulators:
            emulator.optimize_restarts(num_restarts = 3, verbose = False)

class NashvilleHot(Emu):

    def get_data(self, filename, fixed_params, attach_params = False):
        """
        Read data in the format compatible with this object and return it.

        Removing NaNs is not possible, since all data points are needed. Instead,
        they are set to the mean of Y.

        :param filename:
           A .hdf5 file containing the training data, in the format of those generated by trainer.py
        :param fixed_params:
           Parameters to hold fixed during training. Key is the name of the param, value if the value to hold fixed.
           The only parameters that can be fixed are 'cosmo', 'HOD', 'r', and 'z'. 'r' and 'z' can be fixed to floats
           of scale (distance in Mpc, angle in degrees, etc) and redshift respectively.
           Cosmo and HOD can only be fixed to an integer number, representing the index of the cosmo/HOD to hold fixed
           across HODs/Cosmologies respectively. Multiple fixed params can be specified.
        :return: x1, x2, y, yerr,cov all numpy arrays.
                x1 is (n_cosmo_points, n_cosmo_params)
                x2 is (n_hod_points, n_hod_params)
                y is (n_cosmo_points, n_hod_points), yerr is same
                and ycov (n_data_points, n_scale_bins, n_scale_bins), a "list" of covaraince matrices,
                to do with what you will
        """
        assert path.isfile(filename)
        # fixed params can only fix an hod index, cosmo index, or z or r
        assert len(fixed_params) <= 2
        # 'cosmo' and 'hod' not allowed here
        assert all(key in {'z', 'r', 'rmin'} for key in fixed_params)

        f = h5py.File(filename, 'r')

        # get global attributes from the file
        cosmo_param_names = f.attrs['cosmo_param_names']
        hod_param_names = f.attrs['hod_param_names']
        try:
            cosmo_param_vals = f.attrs['cosmo_param_vals']
            hod_param_vals = f.attrs['hod_param_vals']
        except KeyError:
            cosmo_param_vals = np.array(f['attrs/cosmo_param_vals'])
            hod_param_vals = np.array(f['attrs/hod_param_vals'])

        x1, x2 = cosmo_param_vals, hod_param_vals

        scale_factors = f.attrs['scale_factors']
        redshift_bin_centers = 1.0 / scale_factors - 1  # emulator works in z, sims in a.
        if 'z' in fixed_params:
            assert np.any(np.isclose(fixed_params['z'], redshift_bin_centers))

        scale_bins = f.attrs['scale_bins']
        scale_bin_centers = (scale_bins[1:] + scale_bins[:-1]) / 2.0 if scale_bins is not None else None

        rmin = fixed_params['rmin'] if 'rmin' in fixed_params else 0.0
        # instead of fixing values, just ensure values are greater than this values
        gt_rmin = scale_bin_centers > rmin
        scale_bin_centers = scale_bin_centers[gt_rmin]

        if 'r' in fixed_params:
            # this wil also fale if scb is None. but you can't fix when it's none anyway so.
            # may wanna have a friendlier error message htough.
            assert np.any(
                np.abs(fixed_params['r'] - scale_bin_centers) < 1e-4)  # may need to include a fudge factor here
            r_idx = np.argmin(np.abs(fixed_params['r'] - scale_bin_centers))

        # construct ordered_params
        # ordered_params is an ordered dict whose keys are the parameters in the
        # order they are in in the data. The values are their bounds in the training data

        op_names = list(cosmo_param_names[:])
        op_names.extend(hod_param_names)

        min_max_vals = zip(np.r_[cosmo_param_vals.min(axis=0), hod_param_vals.min(axis=0)], \
                           np.r_[cosmo_param_vals.max(axis=0), hod_param_vals.max(axis=0)])
        ordered_params = OrderedDict(izip(op_names, min_max_vals))

        # NOTE if its single_valued, may have to fudge this somehow?
        if 'z' not in fixed_params:
            ordered_params['z'] = (np.min(redshift_bin_centers), np.max(redshift_bin_centers))

        if 'r' not in fixed_params:
            ordered_params['r'] = (np.log10(np.min(scale_bin_centers)), np.log10(np.max(scale_bin_centers)))

        if attach_params:  # attach certain parameters to the object
            self.obs = f.attrs['obs']
            self.redshift_bin_centers = redshift_bin_centers
            self.scale_bin_centers = scale_bin_centers
            self.n_bins = len(scale_bin_centers) if (scale_bin_centers is not None) and ('r' not in fixed_params) else 1
            self._ordered_params = ordered_params
        else:
            # return them
            info = {'obs': f.attrs['obs'],
                    'rbc': redshift_bin_centers,
                    'sbc': scale_bin_centers,
                    'n_bins': len(scale_bin_centers) if (scale_bin_centers is not None) and (
                    'r' not in fixed_params) else 1,
                    'ordered_params': ordered_params
                    }

        # append files to a list, then concatenate at the end
        # note these will have different shapes in this object
        if 'r' in fixed_params:
            y = []
            yerr = []
        else:
            y = [[] for i in xrange(gt_rmin.shape[0]) if gt_rmin[i]]
            yerr = [[] for i in xrange(gt_rmin.shape[0]) if gt_rmin[i]]

        ycov = []

        for cosmo_group_name, cosmo_group in f.iteritems():
            # we're fixed to a particular cosmology #
            if cosmo_group_name == 'attrs':
                continue

            for sf_group_name, sf_group in cosmo_group.iteritems():
                z = 1.0 / float(sf_group_name[-5:]) - 1.0

                if 'z' in fixed_params and np.abs(z - fixed_params['z']) > 1e-3:
                    continue

                obs_dset = sf_group['obs'][()]
                cov_dset = sf_group['cov'][()]

                #print cosmo_group_name, np.where(np.all(obs_dset==0.0, axis = 1))

                if 'r' in fixed_params:
                    y.append(obs_dset[:,r_idx])
                    yerr.append(cov_dset[:, r_idx, r_idx])
                else:
                    for r_idx in xrange(gt_rmin.shape[0]):
                        if not gt_rmin[r_idx]:
                            continue
                        # ugly, but takes the rbin slice and puts it to the corresponding list.
                        y[r_idx - np.sum(~gt_rmin)].append(obs_dset[:, r_idx])
                        yerr[r_idx - np.sum(~gt_rmin)].append(cov_dset[:, r_idx, r_idx])

                        

                # we will be using this differently, so keep this format too.
                for _cov in cov_dset:
                    if 'r' in fixed_params:
                        ycov.append(np.array(_cov[r_idx, r_idx]))

                    else:
                        ycov.append(_cov[gt_rmin, :][:, gt_rmin])


        f.close()

        if 'r' in fixed_params:
            y = np.vstack(y)
            yerr = np.vstack(yerr)
        else:
            y = np.array([np.vstack(_y) for _y in y])
            yerr = np.array([np.vstack(_yerr) for _yerr in yerr])

        _ycov = np.dstack(ycov)

        if (np.any(np.isnan(ycov)) or np.any(np.isnan(y))):
            #y_nans = np.logical_or(np.isnan(y), np.all(y==0.0, axis = 0))
            y_nans = np.isnan(y)
            nan_idxs = np.where(y_nans)  # np.logical_or(y_nans ,ycov_nans )
            #print np.where(nan_idxs)
            num_skipped = np.sum(y_nans)
            for a,b,c in zip(*nan_idxs):
                y[a,b,c] = np.nanmean(y[a])

            #y_nans = np.logical_or(np.isnan(yerr), np.all(yerr==0.0, axis = 0))
            y_nans = np.isnan(yerr)
            nan_idxs = np.where(y_nans)  # np.logical_or(y_nans ,ycov_nans )
            #print np.where(nan_idxs)
            #num_skipped = np.sum(y_nans)
            for a,b,c in zip(*nan_idxs):
                yerr[a,b,c] = np.nanmean(y[a])

            ycov_list = []

            mean_mat = np.nanmean(_ycov, axis = 2)
            for i in xrange(_ycov.shape[-1]):
                mat = _ycov[:, :, i]
                if np.any(np.isnan(mat)):
                    mat = mean_mat
                ycov_list.append(mat)#[~idxs, :][:, ~idxs])

            ycov = ycov_list  # np.dstack(ycov_list)

            warnings.warn('WARNING: NaN detected. Skipped %d points in training data.' % (num_skipped))

        else:
            ycov = _ycov.T

            # stack so xs have shape (n points, n params)
        # ys have shape (npoints)
        # and ycov has shape (n_bins, n_bins, n_points/n_bins)
        y = np.stack(y)
        yerr = np.stack(yerr)
        if len(y.shape) == 2: 
            y = np.expand_dims(y, 0)
            yerr = np.expand_dims(yerr, 0) # make sure they all have the same shape, ain't that nice?

        if attach_params:
            return x1, x2, y, yerr, ycov
        else:
            return x1, x2, y, yerr, ycov, info

    def load_training_data(self, filename, custom_mean_function=None):
        """
        Read the training data for the emulator and attach it to the object.
        :param filename:
            Directory where training data from trainginData is stored.
        :return: None
        """
        assert custom_mean_function is None, "Mean functions not supported for Nashville Hot"

        x1, x2, y, yerr, ycov = self.get_data(filename, self.fixed_params, attach_params=True)
        # store the data loading args, if we wanna reload later
        # useful ofr sampling the training data

        y_std = 1.0  # y.mean(axis = 0), y.std(axis = 0)

        ycov_list = []
        for yc in ycov:
            ycov_list.append(yc / (np.outer(y_std, y_std) + 1e-5))

        ycov = ycov_list
        # if required, could figure out how to get these from teh covs
        # but i'm already fucking up the schema, so may as well make things easy
        #yerr = np.sqrt(np.hstack(np.diag(np.array(syc)) for syc in ycov))

        # in general, the full cov matrix will be too big, and we won't need it. store the diagonal, and
        # an average

        # compute the average covaraince matrix
        self.ycov = np.zeros((self.n_bins, self.n_bins))
        n_right_shape = 0
        # if len(ycov) == 1 and type(ycov) is not list:
        #    for yc in ycov.T:
        #        if yc.shape[0] != self.n_bins:
        #            continue
        #        elif np.any(np.isnan(yc)):
        #            continue
        #        n_right_shape+=1
        #        self.ycov+=yc
        for yc in ycov:
            if yc.shape[0] != self.n_bins:
                continue
            elif np.any(np.isnan(yc)):
                continue

            n_right_shape += 1
            self.ycov += yc

        self.ycov /= n_right_shape

        ndim = x1.shape[1]+x2.shape[1]
        self.emulator_ndim = ndim  # The number of params for the emulator is different than those in sampling.

        #r_idx = self.get_param_names().index('r')
        self.r_idx = ndim # this object doesn't use this, but i think i use this as a marker
        # TODO be smarter about how i split up the multi bin emus vs the OR
        if 'r' in self._ordered_params:
            del self._ordered_params['r']  # remove r!


        #self._x1_mean, self._x1_std = np.zeros((x1.shape[1],)), np.ones((x1.shape[1],))#x1.mean(axis = 0), x1.std(axis = 0)
        self._x1_mean, self._x1_std = x1.mean(axis = 0), x1.std(axis = 0)

        #self._x2_mean, self._x2_std = np.zeros((x2.shape[1],)), np.ones((x2.shape[1],))#x2.mean(axis = 0), x2.std(axis = 0)
        self._x2_mean, self._x2_std = x2.mean(axis = 0), x2.std(axis = 0)


        # TODO x1 & x2 or xcosmo and xhod?
        self.x1, self.x2 = self._whiten(x1, x2)[0] 

        self._y_mean = np.stack([_y.mean() for _y in y] )
        #self._y_mean = np.stack([ 0.0 for _y in y] ) #np.stack([_y.mean() for _y in y] )
        #self._y_std = np.stack([_y.std() for _y in y])
        self._y_std = np.stack([ 1.0 for _y in y]) #np.stack([_y.std() for _y in y])

        self.y  = np.stack([_y-_ym for _y,_ym in zip(y, self._y_mean)])
        self.yerr = np.stack(yerr)

        self.mean_function = self._make_custom_mean_function(custom_mean_function)
        for i, mf in enumerate(self.mean_function(self.x1)):
            self.y[i] -= mf

    def _whiten(self, x1, x2=None):
        """

        :param x:
        :param arr:
        :return:
        """
        if x2 is None:
            if len(x1.shape) == 1:
                x1, x2 = x1[:self.x1.shape[-1]], x1[self.x1.shape[-1]:]
                if x2.shape[0] -1 == self._x2_mean.shape[0]:
                    x2 = x2[:-1]

            else:
                x1, x2 = x1[:, :self.x1.shape[-1]], x1[:, self.x1.shape[-1]:]

                if x2.shape[1] -1 == self._x2_mean.shape[0]:
                    x2 = x2[:, :-1]

        return ((x1-self._x1_mean)/(self._x1_std+1e-9), (x2-self._x2_mean)/(self._x2_std+1e-9)), None

    def _make_custom_mean_function(self, custom_mean_function =None):
        """
        Not supported for this class, will throw error if something is tried
        :param custom_mean_function:
            Throws error for non-None answers
        :return:
        """
        if custom_mean_function is None:
            return lambda x: np.zeros((self.n_bins),) 
        else:
            raise NotImplementedError("Custom mean functions not supported for Nashville Hot.")

    def _downsample_data(self, downsample_factor, x1, x2, y, yerr, attach = True):

        downsample_y = []
        downsample_yerr = []
        if x1.shape[0] > x2.shape[0]:
            #downsample x1
            N_points = x1.shape[0]
            downsample_N_points = int(downsample_factor*N_points)
            downsample_x1 = x1[:downsample_N_points, :]
            downsample_x2 = x2

            for i in xrange(self.n_bins):
                downsample_y.append(y[i, :downsample_N_points,:])
                downsample_yerr.append(yerr[i, :downsample_N_points,:])

        else: #downsample x2
            N_points = x2.shape[0]
            downsample_N_points = int(self._downsample_factor * N_points)
            downsample_x2 = x2[:downsample_N_points, :]
            downsample_x1 = x1

            for i in xrange(self.n_bins):
                downsample_y.append(y[i, :, :downsample_N_points])
                downsample_yerr.append(yerr[i, :, :downsample_N_points])

        if attach:
            self.downsample_x1 = np.stack(downsample_x1)
            self.downsample_x2 = np.stack(downsample_x2)
            self.downsample_y = np.stack(downsample_y)
            self.downsample_yerr = np.stack(downsample_yerr)
        else:
            return downsample_x1, downsample_x2, np.stack(downsample_y), np.stack(downsample_yerr)
    def check_param_names(self, param_names, ignore=[]):
        #see above, just adding 'r' to ignore by default
        ig = ['r'] if 'r' not in ignore else []
        ig.extend(ignore)
        return super(NashvilleHot, self).check_param_names(param_names, ig)


    def _build_gp(self, hyperparams):
        """
        Initialize the GP emulator model.
        :param hyperparams:
            Key word parameters for the emulator
        :return: None
        """
        output = self._make_kernel(hyperparams)

        if len(output) == 2:
            kern1, kern2 = output
            noise_var = 1.0

        elif len(output) == 3:
            kern1, kern2, noise_var = output

        else:
            kern1, kern2, noise_var = [],[], []
            if len(output[0]) == 2:
                for k1, k2 in output:
                    kern1.append(k1)
                    kern2.append(k2)
                    noise_var.append(1.0)

            else:
                for k1, k2, nv in output:
                    kern1.append(k1)
                    kern2.append(k2)
                    noise_var.append(nv)

        if type(kern1) is not list:
            kern1 = [kern1.copy() for i in xrange(self.n_bins)]

        if type(kern2) is not list:
            kern2 = [kern2.copy() for i in xrange(self.n_bins)]

        if type(noise_var) is not list:
            noise_var = [noise_var for i in xrange(self.n_bins)]

        # now, make a list of emulators
        self._emulators = []
        self._kernels = []

        # yerr taken care of in kernel
        if self._downsample_factor == 1.0:
            x1, x2 = self.x1, self.x2
            y = self.y
            yerr = self.yerr
        else:
            x1, x2 = self.downsample_x1, self.downsample_x2
            y = self.downsample_y
            yerr = self.downsample_yerr

        for _y,_yerr, _kern1, _kern2, nv in izip(y,yerr, kern1, kern2, noise_var):
            # TODO delete me
            #emulator = GPKroneckerGaussianRegressionVar([x1, x2], _y, _yerr**2, _kern1, _kern2, noise_var = nv)
            emulator = GPKroneckerGaussianRegression([x1, x2], _y, [_kern1, _kern2])

            self._emulators.append(emulator)
            self._kernels.append((_kern1, _kern2))

    def _build_skl(self, hyperparams):
        warnings.warn("NashvilleHot does not provide advantages for skl mode, so it is not reccomended.")
        super(NashvilleHot, self)._build_skl(hyperparams)

    def _get_default_kernel(self):
        # TODO I should save these under the emu name, so different kernels don't overlap
        f = h5py.File(self.filename, 'r')
        if 'nh_kernel' in f.attrs: 
           kernel_dict =f.attrs['nh_kernel']
        else:
            raise KeyError("No default saved for this observable!")
        f.close()

        return self._kernel_from_dict(kernel_dict)

        # this has problems for xied binning schemees...
        # Don't know how to make this work with the new kernel schemes, or cosmology.

        # if type(metric) is list:
        #
        #     for bin_metric in metric:
        #         for key in self._ordered_params:
        #             if key not in bin_metric:
        #                bin_metric[key] = 1.0
        #
        #         # remove entries for variables that are being held fixed.
        #         for key in self.fixed_params.iterkeys():
        #             if key in bin_metric:
        #                 del bin_metric[key]
        # else:
        #     for key in self._ordered_params:
        #         if key not in metric:
        #            metric[key] = 1.0
        #
        #     # remove entries for variables that are being held fixed.
        #     for key in self.fixed_params.iterkeys():
        #         if key in metric:
        #                 del metric[key]
        #
        #return kernel

    def _kernel_from_dict(self, kernel_dict):
        # TODO not sure if here or somewhere else, but
        # would be nice to pass in a kernel type and have object figure out the ndim values.
        # would probably have to work off a keyword dict
        if type(kernel_dict) is str:
            kernel_dict = literal_eval(kernel_dict)

        if type(kernel_dict) is list:
            if type(kernel_dict[0]) in (tuple, list): # 2D
                if len(kernel_dict[0]) == 2:
                    return [[Kern.from_dict(kd[0]), Kern.from_dict(kd[1])] for kd in kernel_dict]
                else: #3?
                    return [[Kern.from_dict(kd[0]), Kern.from_dict(kd[1]), float(kd[2])] for kd in kernel_dict]
            return [Kern.from_dict(kd) for kd in kernel_dict]
        return Kern.from_dict(kernel_dict)

    def save_as_default_kernel(self):
        # TODO how to clip of tye Yvar portion
        if hasattr(self, '_kernel'):
            kernel_dict = self._kernel.to_dict()
        elif hasattr(self, '_kernels'):
            if type(self._kernels[0]) in (tuple, list): #2D
                if len(self._kernels[0]) == 2:
                    kernel_dict = [[_k[0].to_dict(), _k[1].to_dict()] for _k in self._kernels]
                else: #d
                    kernel_dict = [[_k[0].to_dict(), _k[1].to_dict(), _k[2]] for _k in self._kernels]
            else:
                kernel_dict = [_k.to_dict() for _k in self._kernels]
        else:
            raise AssertionError("No emulator loaded, cannot save.")

        f = h5py.File(self.filename)
        f.attrs['nh_kernel'] = str(kernel_dict)
        f.close()

    def _make_kernel(self, hyperparams):
        """
        Helper method to build a george kernel for GP's and kernel-based regressions.
        :param metric:
            Hyperparams for kernel determining relative length scales and amplitudes. Default is empty dict.
            In that case, the initial guesses from the object will be used.
        :return:
            A george ExpSquredKernel object with this metric
        """

        # I'm gonna try having the user build a kernel and pass it in, else defaults passed to default kenrel
        # lots of ways to take this but i'm just not feeling most of them
        try:
            if 'kernel' in hyperparams and type(hyperparams['kernel']) not in (dict, list, tuple):
                assert isinstance(hyperparams['kernel'], Kern)
                return hyperparams['kernel'], hyperparams['kernel'].copy()

            elif 'kernel' in hyperparams:  # is a dict from GPy, or a collection
                if type(hyperparams['kernel']) is dict: #describes one kernel
                    k = self._kernel_from_dict(hyperparams['kernel'])
                    return k, k.copy()
                elif len(hyperparams['kernel']) == 2: #one for each?
                    k = hyperparams['kernel']
                    if type(k[0]) is dict:
                        return self._kernel_from_dict(k[0]), self._kernel_from_dict(k[1])
                    else: 
                        assert isinstance(hyperparams['kernel'][0], Kern)
                        return hyperparams['kernel']
                elif len(hyperparams['kernel']) == 3: #one for each+ a var?
                    k = hyperparams['kernel']
                    if type(k[0]) is dict:
                        return self._kernel_from_dict(k[0]), self._kernel_from_dict(k[1]), float(k[2])
                    else: 
                        assert isinstance(hyperparams['kernel'][0], Kern)
                        return hyperparams['kernel']

                # else, idk hope its right
                # TODO better checks, corrections here
                return self._kernel_from_dict(hyperparams['kernel'])
            else:
                return self._get_default_kernel()
        except AssertionError:
            raise AssertionError("Input kernels incorrectly specified! ")

    def _emulate_helper(self, t, gp_errs=False, old_idxs=None):
        """
        Helper function that takes a dependent variable matrix and makes a prediction.
        :param t:
            Dependent variable matrix. Assumed to be in the order defined by ordered_params
        :param gp_errs:
            Whether or not to return errors in the gp case
        :return:
            mu, err (if gp_errs True). Predicted value for dependetn variable t.
            mu and err both have shape (npoints*self.redshift_bin_centers*self.scale_bin_centers)
        """
        assert old_idxs is None, "Old_idxs not supported, not sure how you even got here!"
        #
        t1, t2 = t
        mean_func_at_params = self.mean_function(t)

        mu = []
        err = []

        # TOOD these are all the same now, any way to simplify?
        for bin_no, (t1_in_bin, t2_in_bin,  mfc, emulator) in enumerate(izip(t1, t2, mean_func_at_params, self._emulators)):

            #print t1_in_bin
            #print t2_in_bin
            if self.method == 'gp':
                # because were using a custom object here, don't have to do the copying stuff
                # however, have to split up t into the two groups
                #TODO may have weird behavior for larger t's? have to do some resizing
                if gp_errs:
                    local_mu, local_err = emulator.predict([t1_in_bin.reshape((1,-1)), t2_in_bin.reshape((1,-1))])
                else:
                    local_mu, _ = emulator.predict([t1_in_bin.reshape((1,-1)), t2_in_bin.reshape((1,-1))])
                    # print local_mu
                    local_err = np.ones_like(local_mu)

            else:
                local_mu = emulator.predict(t_in_bin)
                local_err = np.ones_like(local_mu)  # weight with this instead of the errors.

            # print 'local_mu, mfc', local_mu, mfc
            mu.append(self._y_std[bin_no] * (local_mu + mfc) + self._y_mean[bin_no])
            err.append(local_err * self._y_std[bin_no])

        # now, figure out how to return to the shape of t
        combined_mu = np.vstack(mu)#np.zeros((t_size,))
        combined_err = np.vstack(mu)#np.zeros((t_size,))
        
        #for r_idx in xrange(self.n_bins):
        #    combined_mu[r_idx::self.n_bins] = mu[r_idx]
        #    combined_err[r_idx::self.n_bins] = err[r_idx]

        # Reshape to be consistent with my other implementation
        if not gp_errs:
            return combined_mu

        return combined_mu, combined_err

    def goodness_of_fit(self, truth_file, downsample_factor=None, statistic='r2'):
        """
            Calculate the goodness of fit of an emulator as compared to some validation data.
            :param truth_dir:
            Directory structured similarly to the training data, but NOT used for training.
            :param N:
            Number of points to use to calculate G.O.F. measures. "None" tests against all values in truth_dir. If N
            is less than the number of points, N are randomly selected. Default is None.
            :param statistic:
            What G.O.F. statistic to calculate. Default is r2. Other options are rmsfd, abs(olute), and rel(ative).
            :return: values, a numpy arrray of the calculated statistics at each of the N training points.
            """
        assert statistic in {'r2', 'rms', 'rmsfd', 'abs', 'log_abs', 'frac', 'log_frac', None}
        if downsample_factor is not None:
            assert downsample_factor > 0 and downsample_factor<=1.0

        x1, x2, y, yerr, _, info = self.get_data(truth_file, self.fixed_params)
        x1, x2 = self._whiten(x1, x2)[0]

        scale_bin_centers = info['sbc']
        scale_nbins = len(scale_bin_centers) if 'r' not in self.fixed_params else 1

        np.random.seed(int(time()))

        if downsample_factor is not None and downsample_factor<1.0:  # make a random choice
            x1, x2, y, yerr = self._downsample_data(downsample_factor, x1, x2, y, yerr, attach = False)

        #pred_y = self._emulate_helper(x, False, old_idxs=old_idxs)
        # emulate helper works better for one at a time
        # since were doing a big batch, dont' bother builind the big t-matrix
        #_py = [emu.predict(x1, x2)[0][:, 0] + ym for emu, ym in zip(self._emulators, self._y_mean)]
        pred_ys = []
        # there can be memory issues with trying to this all at once.
        for _x2 in x2:
            _py = [emu.predict([x1, _x2.reshape((1, -1))])[0].squeeze() + ym for emu, ym in zip(self._emulators, self._y_mean)]
            pred_ys.append(np.stack(_py))

        pred_y = np.hstack(pred_ys)#.T
        # NOTE think this is the right ordering, should check, though may not matter if i'm consistent...

        # TODO untested!
        if np.any(scale_bin_centers != self.scale_bin_centers):
            bin_centers = scale_bin_centers[self.scale_bin_centers[0] <= scale_bin_centers <= self.scale_bin_centers[-1]]
            new_mu = []
            for mean in pred_y:
                xi_interpolator = interp1d(self.scale_bin_centers, mean, kind='slinear')
                interp_mean = xi_interpolator(bin_centers)
                new_mu.append(interp_mean)
            pred_y = np.array(new_mu)
            y = y[:, self.scale_bin_centers[0] <= bin_centers <= self.scale_bin_centers[-1]]

        if statistic is None:
            return pred_y, y.reshape((y.shape[0], -1), order = 'F')

        y = y.reshape((y.shape[0], -1), order = 'F')

        if statistic == 'rmsfd':
            return np.sqrt(np.mean((((pred_y - y) ** 2) / (y ** 2)), axis=0))

        elif statistic == 'rms':
            return np.sqrt(np.mean(((pred_y - y) ** 2), axis=0))

        # TODO sklearn methods can do this themselves. But i've already tone the prediction!
        elif statistic == 'r2':  # r2
            SSR = np.sum((pred_y - y) ** 2, axis=0)
            SST = np.sum((y - y.mean(axis=0)) ** 2, axis=0)

            return 1 - SSR / SST

        elif statistic == 'abs':
            return 10 ** pred_y - 10 ** y
            # return np.mean(10 ** pred_y - 10 ** y, axis = 0)
        elif statistic == 'log_abs':
            return pred_y - y
            # return np.mean((pred_y - y), axis=0)
        elif statistic == 'log_frac':  # 'rel'
            out = np.abs(pred_y - y) / np.abs(y)
            return out
            # return np.mean((pred_y - y) / y, axis=0)
        else:  # 'frac'
            out = np.abs(10 ** pred_y - 10 ** y) / np.abs(10 ** y)
            return out

    def _emulator_lnlikelihood(self):
        """
        """
        assert self.method == 'gp'

        # TODO figure out gradient as well
        ll = 0
        gll = 0

        for idx, emulator in enumerate(self._emulators ):
            ll += emulator.log_likelihood()#
            gll += emulator.log_likelihood_grad()

        # The scipy optimizer doesn't play well with infinities.

        ll = ll if np.isfinite(ll) else -1e25

        return ll, gll

    def train_metric(self, p0=None,  **kwargs):
        """
        Train the emulator. Has a spotty record of working. Better luck may be had with the NAMEME code.
        :param kwargs:
            Kwargs that will be passed into the scipy.optimize.minimize
        :return: success: True if the training was successful.
        """

        assert self.method == 'gp'

        for idx, emulator in enumerate(self._emulators):
            print idx, '*'*15
            try:
                emulator.optimize_restarts(parallel=True, num_restarts = 3, verbose = True, robust=True)
            except:
                emulator.optimize_restarts(parallel=False, num_restarts = 3, verbose = True, robust=True)
            sys.stdout.flush()


# TODO
# This should be the EMU superclass, to avoid the ABC crap
# class Ostrich(Emu):
#     """
#     Simplified emu that doesnt build an emulator. Useful for data manipulation
#     """
#     def __init__(self, filename, method='gp',  fixed_params={}, downsample_factor=1.0, custom_mean_function=None):
#
#         assert method in self.valid_methods
#
#         self.method = method
#
#         self.fixed_params = fixed_params
#         self._downsample_factor = downsample_factor
#
#         self.load_training_data(filename, custom_mean_function)

# This will be retired because A. it didn't work that well and B. it doesn't work with GPy
# class LemonPepperWet(SpicyBuffalo):
#     """
#     A modification of SpicyBuffalo to use one emu across all bins.
#     """
#
#     def load_training_data(self, filename, custom_mean_function=None):
#         """
#         Read the training data for the emulator and attach it to the object.
#         :param training_dir:
#             Directory where training data from trainginData is stored.
#         :param fixed_params:
#             Parameters to hold fixed. Only available if data in training_dir is a full hypercube, not a latin hypercube.
#         :return: None
#         """
#         # make sure we attach metadata to the object
#         x, y, ycov = self.get_data(filename, self.fixed_params, attach_params=True, remove_nans = False)
#
#         # store the data loading args, if we wanna reload later
#         # useful ofr sampling the training data
#
#         y_std = 1.0  # y.mean(axis = 0), y.std(axis = 0)
#
#         ycov_list = []
#         for yc in ycov:
#             ycov_list.append(yc / (np.outer(y_std, y_std) + 1e-5))
#
#         ycov = ycov_list
#         yerr = np.sqrt(np.hstack(np.diag(np.array(syc)) for syc in ycov))
#
#         # in general, the full cov matrix will be too big, and we won't need it. store the diagonal, and
#         # an average
#
#         # compute the average covaraince matrix
#         self.ycov = np.zeros((self.n_bins, self.n_bins))
#         n_right_shape = 0
#         # if len(ycov) == 1 and type(ycov) is not list:
#         #    for yc in ycov.T:
#         #        if yc.shape[0] != self.n_bins:
#         #            continue
#         #        elif np.any(np.isnan(yc)):
#         #            continue
#         #        n_right_shape+=1
#         #        self.ycov+=yc
#         for yc in ycov:
#             if yc.shape[0] != self.n_bins:
#                 continue
#             elif np.any(np.isnan(yc)):
#                 continue
#
#             n_right_shape += 1
#             self.ycov += yc
#
#         self.ycov /= n_right_shape
#
#         ndim = x.shape[1] - 1
#         self.emulator_ndim = ndim  # The number of params for the emulator is different than those in sampling.
#
#         # we have to have lists, since some may have been dropped due to Nans.
#         # There's definetly a better way to do this ...
#         self.x = []
#         self.y = []
#         self.yerr = []
#
#         self._x_mean, self._x_std = [], []
#         self._y_mean, self._y_std = np.zeros((self.n_bins,)), np.ones((self.n_bins,))  # [], []
#
#         r_idx = self.get_param_names().index('r')
#         self.r_idx = r_idx  # we'll need this later, too
#         del self._ordered_params['r']  # remove r!
#
#         skip_r_idx = np.ones((x.shape[1]), dtype=bool)
#         skip_r_idx[r_idx] = False
#
#         # select the non-r x's for one bin
#         bin_idxs = np.isclose(np.log10(self.scale_bin_centers[0]), x[:, r_idx])
#
#         # do the x stuff one time, then copy
#         x_in_bin = x[bin_idxs, :][:, skip_r_idx]
#
#         x_mean, x_std = x_in_bin.mean(axis=0), x_in_bin.std(axis=0)
#         norm_x = (x_in_bin - x_mean) / (x_std + 1e-5)
#
#         # TODO a better yerr strategy for this hack
#         # I do think it's small enough as to no matter
#         yerr_one_bin = yerr[bin_idxs]
#         yerr_one_bin[np.isnan(yerr_one_bin)] = np.nanmin(yerr_one_bin)
#
#         for bin_no, sbc in enumerate(np.log10(self.scale_bin_centers)):
#             bin_idxs = np.isclose(sbc, x[:, r_idx])
#
#             y_in_bin = y[bin_idxs]
#
#             if type(self._y_mean) is list:  # don't do the calculation if we've decided we don't whiten y
#                 y_mean, y_std = y_in_bin.nanmean(), y_in_bin.nanstd()
#             else:
#                 y_mean, y_std = self._y_mean[bin_no], self._y_std[bin_no]
#
#             # TODO is this the best way to deal with NaNs?
#             y_in_bin[np.isnan(y_in_bin)] = y_mean
#
#             self.x.append(norm_x)
#             self.y.append((y_in_bin - y_mean) / (y_std + 1e-5))
#             #self.yerr.append(np.ones_like(yerr_one_bin)*1e-6)
#             self.yerr.append(yerr_one_bin)
#
#             self._x_mean.append(x_mean)
#             self._x_std.append(x_std)
#
#             if type(self._y_mean) is list:
#                 self._y_mean.append(y_mean)
#                 self._y_std.append(y_std)
#
#
#         self.mean_function = self._make_custom_mean_function(custom_mean_function)
#         for i, mf in enumerate(self.mean_function(self.x)):
#             self.y[i] -= mf
#
#
#     def _downsample_data(self):
#
#         N_points = max(
#             [_x.shape[0] for _x in self.x])  # don't sample full HOD/cosmo points. Already broken up in experts
#
#         downsample_N_points = int(self._downsample_factor * N_points)
#         downsampled_points = np.random.choice(len(self.x[0]), downsample_N_points, replace=False)
#
#         downsample_x = np.zeros((downsample_N_points, self.x[0].shape[1]))
#         downsample_yerr = np.zeros((downsample_N_points,))
#
#         for i, dp in enumerate(downsampled_points):
#             downsample_x[i:(i + 1)] = self.x[0][dp: (dp + 1)]
#             downsample_yerr[i:(i+1)] = self.yerr[0][dp:(dp+1)]
#
#         self.downsample_x = []
#         self.downsample_y = [np.zeros((downsample_N_points,)) for i in xrange(self.n_bins)]
#         self.downsample_yerr = []
#
#         for e in xrange(self.n_bins):
#             self.downsample_x.append(downsample_x)
#             self.downsample_yerr.append(downsample_yerr)
#
#             for i, dp in enumerate(downsampled_points):
#                 self.downsample_y[e][i:(i + 1)] = self.y[e][dp: (dp + 1)]
#
#     def _build_gp(self, hyperparams):
#         """
#         Initialize the GP emulator using an MOE model.
#         :param hyperparams:
#             Key word parameters for the emulator
#         :return: None
#         """
#         kernel = self._make_kernel(hyperparams)
#
#         # now, make a list of emulators
#         self._emulators = []
#
#         if self._downsample_factor == 1.0:
#             x = self.x
#             yerr = self.yerr
#         else:
#             x = self.downsample_x
#             yerr = self.downsample_yerr
#
#         x, yerr = x[0], yerr[0] # only need one bin
#
#         emulator = george.GP(kernel)
#
#         # TODO remoinv the HPs, may be a mistake
#
#         emulator.compute(x, yerr)  # ,**hyperparams)
#
#         for i in xrange(self.n_bins):
#             self._emulators.append(emulator)
#
#     def _build_skl(self, hyperparams):
#         warnings.warn("LemonPepperWet does not provide advantages for skl mode, so it is not reccomended.")
#         super(LemonPepperWet, self)._build_skl(hyperparams)

