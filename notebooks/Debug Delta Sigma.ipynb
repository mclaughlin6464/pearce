{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I fixed the TPCF issues, but now the delta sigma projection integration is being troublesome. I'm gonna do them for a few rp_bins to figure out what is sensible agian. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pearce.mocks.kittens import DarkSky\n",
    "from pearce.mocks import tpcf as pearce_tpcf\n",
    "from halotools.mock_observables import tpcf as halotools_tpcf\n",
    "from halotools.empirical_models import Zheng07Cens, Zheng07Sats\n",
    "from collections import OrderedDict\n",
    "from time import time\n",
    "from scipy.optimize import minimize_scalar\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dir = './'# '/home/users/swmclau2/Git/pearce/bin/covmat/ds14_covmat/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config_fname = 'xi_cosmo_trainer.yaml'\n",
    "\n",
    "with open(path.join(output_dir, config_fname), 'r') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile)\n",
    "\n",
    "nd = float(cfg['HOD']['fixed_nd'] )\n",
    "min_ptcl = int(cfg['HOD']['min_ptcl'])\n",
    "r_bins = np.array(cfg['observation']['bins'] ).astype(float)\n",
    "\n",
    "hod_param_ranges =  cfg['HOD']['ordered_params']\n",
    "\n",
    "\n",
    "logMmin_bounds = hod_param_ranges['logMmin']\n",
    "\n",
    "\n",
    "del hod_param_ranges['logMmin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_LHC(ordered_params, N, seed = None):\n",
    "\n",
    "    if seed is None:\n",
    "        seed = int(time())\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    points = []\n",
    "    # by linspacing each parameter and shuffling, I ensure there is only one point in each row, in each dimension.\n",
    "    for plow, phigh in ordered_params.itervalues():\n",
    "        point = np.linspace(plow, phigh, num=N)\n",
    "        np.random.shuffle(point)  # makes the cube random.\n",
    "        points.append(point)\n",
    "    return np.stack(points).T\n",
    "\n",
    "\n",
    "def add_logMmin(hod_params, cat):\n",
    "\n",
    "    hod_params['logMmin'] = 13.0 #initial guess\n",
    "    #cat.populate(hod_params) #may be overkill, but will ensure params are written everywhere\n",
    "    def func(logMmin, hod_params):\n",
    "        hod_params.update({'logMmin':logMmin})\n",
    "        return (cat.calc_analytic_nd(hod_params, min_ptcl = min_ptcl) - nd)**2\n",
    "\n",
    "    res = minimize_scalar(func, bounds = logMmin_bounds, args = (hod_params,), options = {'maxiter':100}, method = 'Bounded')\n",
    "\n",
    "    # assuming this doens't fail\n",
    "    #print 'logMmin', res.x\n",
    "    hod_params['logMmin'] = res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pearce.mocks.kittens import TestBox\n",
    "cat = TestBox(boxno = 0, realization = 0, system = 'ki-ls')\n",
    "cat.load(1.0, HOD='zheng07', particles = True, downsample_factor = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO seed here for constant HODs\n",
    "# TODO maybe just do 5, 10 may be overkill\n",
    "N = 10\n",
    "LHC = make_LHC(hod_param_ranges, N, 24)\n",
    "hod_dicts = [dict(zip(hod_param_ranges.keys(), vals)) for vals in LHC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/ki/swmclau2/.local/lib/python2.7/site-packages/halotools-0.7.dev5005-py2.7-linux-x86_64.egg/halotools/empirical_models/phase_space_models/analytic_models/monte_carlo_helpers.py:205: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  self.rad_prof_func_table_indices[digitized_param_list]\n",
      "/u/ki/swmclau2/.local/lib/python2.7/site-packages/halotools-0.7.dev5005-py2.7-linux-x86_64.egg/halotools/empirical_models/phase_space_models/analytic_models/monte_carlo_helpers.py:522: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  self.rad_prof_func_table_indices[digitized_param_list]\n"
     ]
    }
   ],
   "source": [
    "cat.populate(hod_dicts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rp_bins = np.logspace(-1.1, 1.6, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ombh2', 'omch2', 'w0', 'ns', 'ln10As', 'H0', 'Neff'],\n",
       " array([ 2.32629e-02,  1.07830e-01, -7.26513e-01,  9.80515e-01,\n",
       "         3.03895e+00,  6.32317e+01,  2.95000e+00]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat._get_cosmo_param_names_vals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from halotools.mock_observables import return_xyz_formatted_array, delta_sigma, tpcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_ds(cat, bins):\n",
    "    #n_cores = self._check_cores(n_cores)\n",
    "    n_cores = 2\n",
    "    \n",
    "    x_g, y_g, z_g = [cat.model.mock.galaxy_table[c] for c in ['x', 'y', 'z']]\n",
    "    pos_g = return_xyz_formatted_array(x_g, y_g, z_g, period=cat.Lbox)\n",
    "\n",
    "    x_m, y_m, z_m = [cat.halocat.ptcl_table[c] for c in ['x', 'y', 'z']]\n",
    "    pos_m = return_xyz_formatted_array(x_m, y_m, z_m, period=cat.Lbox)\n",
    "\n",
    "    rp_bins = bins #if not angular else self._rp_from_ang(bins)\n",
    "\n",
    "    # Halotools wnats downsampling factor defined oppositley\n",
    "    # TODO verify little h!\n",
    "    # TODO maybe split into a few lines for clarity\n",
    "    return delta_sigma(pos_g / cat.h, pos_m / cat.h, cat.pmass / cat.h,\n",
    "                   downsampling_factor=1. / cat._downsample_factor, rp_bins=rp_bins,\n",
    "                   period=cat.Lbox / cat.h, num_threads=n_cores, cosmology=cat.cosmology)[1] / (1e12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "import pyccl as ccl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_ds_analytic(cat, bins, xi = None, rbins = None):    \n",
    "    n_cores = 2#self._check_cores(n_cores)\n",
    "    # calculate xi_gg first\n",
    "    xi_kwargs = {}\n",
    "    if xi is None:\n",
    "        assert rbins is None\n",
    "        rbins = np.logspace(-1.3, 1.6, 16)\n",
    "        xi = cat.calc_xi_gm(rbins, n_cores=n_cores, **xi_kwargs)\n",
    "    else:\n",
    "        assert rbins is not None, \"Must specify rbins along with xi\"\n",
    "\n",
    "    if np.any(xi <= 0):\n",
    "        warnings.warn(\n",
    "            \"Some values of xi are less than 0. Setting to a small nonzero value. This may have unexpected behavior, check your HOD\")\n",
    "        xi[xi <= 0] = 1e-3\n",
    "\n",
    "    rpoints = (rbins[:-1] + rbins[1:]) / 2.0\n",
    "    xi_rmin, xi_rmax = rpoints[0], rpoints[-1]\n",
    "\n",
    "    # make an interpolator for integrating\n",
    "    xi_interp = interp1d(np.log10(rpoints), np.log10(xi))\n",
    "\n",
    "    # get the theotertical matter xi, for large scale estimates\n",
    "    names, vals = cat._get_cosmo_param_names_vals()\n",
    "    param_dict = {n: v for n, v in zip(names, vals)}\n",
    "    if 'omch2' in param_dict: # in other units, convert\n",
    "        new_param_dict = {}\n",
    "        new_param_dict['Omega_c'] = param_dict['omch2']*cat.h**2\n",
    "        new_param_dict['Omega_b'] = param_dict['ombh2']*cat.h**2\n",
    "        new_param_dict['n_s'] = param_dict['ns']\n",
    "        new_param_dict['h'] = cat.h\n",
    "        new_param_dict['A_s'] = np.exp(param_dict['ln10As'])/(np.power(10, 10))\n",
    "\n",
    "        param_dict = new_param_dict\n",
    "\n",
    "    \n",
    "    elif 'Omega_c' not in param_dict:\n",
    "        param_dict['Omega_c'] = param_dict['Omega_m'] - param_dict['Omega_b']\n",
    "        del param_dict['Omega_m']\n",
    "\n",
    "    cosmo = ccl.Cosmology(**param_dict)\n",
    "\n",
    "    big_rbins = np.logspace(1, 2.3, 21)\n",
    "    big_rpoints = (big_rbins[1:] + big_rbins[:-1]) / 2.0\n",
    "    big_xi_rmax = big_rpoints[-1]\n",
    "    xi_mm = ccl.correlation_3d(cosmo, cat.a, big_rpoints)\n",
    "\n",
    "    xi_mm[xi_mm < 0] = 1e-6  # may wanna change this?\n",
    "    xi_mm_interp = interp1d(np.log10(big_rpoints), np.log10(xi_mm))\n",
    "\n",
    "    # correction factor\n",
    "    bias = np.power(10, xi_interp(1.2) - xi_mm_interp(1.2))\n",
    "    rhocrit = cat.cosmology.critical_density(0).to('Msun/(Mpc^3)').value\n",
    "    rhom = cat.cosmology.Om(0) * rhocrit * 1e-12  # SM h^2/pc^2/Mpc; integral is over Mpc/h\n",
    "\n",
    "    def sigma_integrand_medium_scales(lRz, Rp, xi_interp):\n",
    "        Rz = np.exp(lRz)\n",
    "        print \"Med\", Rz, Rp, rpoints[0]\n",
    "        return Rz * 10 ** xi_interp(np.log10(Rz * Rz + Rp * Rp) * 0.5)\n",
    "\n",
    "    def sigma_integrand_large_scales(lRz, Rp, bias, xi_mm_interp):\n",
    "        Rz = np.exp(lRz)\n",
    "        print \"Large\", Rz, Rp, rpoints[0]\n",
    "        return Rz * bias * 10 ** xi_mm_interp(np.log10(Rz * Rz + Rp * Rp) * 0.5)\n",
    "\n",
    "    ### calculate sigma first###\n",
    "\n",
    "    sigma_rpoints = np.logspace(-1.0, 2.2, 15)\n",
    "\n",
    "    sigma = np.zeros_like(sigma_rpoints)\n",
    "    for i, rp in enumerate(sigma_rpoints):\n",
    "        log_u_ss_max = np.log(xi_rmax ** 2 - rp ** 2) / 2.0  # Max distance to integrate to\n",
    "        log_u_ls_max = np.log(big_xi_rmax ** 2 - rp ** 2) / 2.0  # Max distance to integrate to\n",
    "\n",
    "        if not np.isnan(log_u_ss_max):  # rp > xi_rmax\n",
    "            small_scales_contribution = \\\n",
    "                    quad(sigma_integrand_medium_scales, -10, log_u_ss_max, args=(rp, xi_interp))[0]\n",
    "            Rz = np.exp(log_u_ls_max)\n",
    "\n",
    "            large_scales_contribution = quad(sigma_integrand_large_scales, log_u_ss_max, log_u_ls_max, \\\n",
    "                                             args=(rp, bias, xi_mm_interp))[0]\n",
    "        elif not np.isnan(log_u_ls_max):\n",
    "            small_scales_contribution = 0\n",
    "            large_scales_contribution = quad(sigma_integrand_large_scales, np.log(xi_rmax), log_u_ls_max, \\\n",
    "\n",
    "                                                                                              args=(rp, bias, xi_mm_interp))[0]\n",
    "        else:\n",
    "            small_scales_contribution = large_scales_contribution = 0.0\n",
    "\n",
    "        assert not any(np.isnan(c) for c in\n",
    "                       (small_scales_contribution, large_scales_contribution)), \"NaN found, aborting calculation\"\n",
    "        sigma[i] = (small_scales_contribution + large_scales_contribution) * rhom * 2;\n",
    "\n",
    "    sigma_interp = interp1d(np.log10(sigma_rpoints), sigma)\n",
    "\n",
    "    ### calculate delta sigma ###\n",
    "\n",
    "    def DS_integrand_medium_scales(lR, sigma_interp):\n",
    "        print 'DS', np.exp(lR), rp_points[0]\n",
    "        return np.exp(2 * lR) * sigma_interp(np.log10(np.exp(lR)))\n",
    "\n",
    "    rp_bins = bins #if not angular else cat._rp_from_ang(bins)\n",
    "\n",
    "    rp_points = (rp_bins[1:] + rp_bins[:-1]) / 2.0\n",
    "    lrmin = np.log(rp_points[0])\n",
    "    ds = np.zeros_like(rp_points)\n",
    "\n",
    "    for i, rp in enumerate(rp_points):\n",
    "        result = quad(DS_integrand_medium_scales, lrmin, np.log(rp), args=(sigma_interp,))[0]\n",
    "        # print result, rp, sigma_interp(np.log10(rp))\n",
    "# print result, rp, sigma_interp(np.log10(rp))\n",
    "        ds[i] = result * 2 / (rp ** 2) - sigma_interp(np.log10(rp))\n",
    "\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ombh2', 'omch2', 'w0', 'ns', 'ln10As', 'H0', 'Neff'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.cosmo_params.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds_analytic = calc_ds_analytic(cat, rp_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = calc_ds(cat, rp_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rpoints = (rp_bins[1:] + rp_bins[:-1])/2.0\n",
    "plt.plot(rpoints, ds.squeeze())\n",
    "plt.loglog();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
