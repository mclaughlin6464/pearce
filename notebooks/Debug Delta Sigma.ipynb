{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I fixed the TPCF issues, but now the delta sigma projection integration is being troublesome. I'm gonna do them for a few rp_bins to figure out what is sensible agian. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pearce.mocks.kittens import DarkSky\n",
    "from pearce.mocks import tpcf as pearce_tpcf\n",
    "from halotools.mock_observables import tpcf as halotools_tpcf\n",
    "from halotools.empirical_models import Zheng07Cens, Zheng07Sats\n",
    "from collections import OrderedDict\n",
    "from time import time\n",
    "from scipy.optimize import minimize_scalar\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dir = './'# '/home/users/swmclau2/Git/pearce/bin/covmat/ds14_covmat/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config_fname = 'xi_cosmo_trainer.yaml'\n",
    "\n",
    "with open(path.join(output_dir, config_fname), 'r') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile)\n",
    "\n",
    "nd = float(cfg['HOD']['fixed_nd'] )\n",
    "min_ptcl = int(cfg['HOD']['min_ptcl'])\n",
    "r_bins = np.array(cfg['observation']['bins'] ).astype(float)\n",
    "\n",
    "hod_param_ranges =  cfg['HOD']['ordered_params']\n",
    "\n",
    "\n",
    "logMmin_bounds = hod_param_ranges['logMmin']\n",
    "\n",
    "\n",
    "del hod_param_ranges['logMmin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_LHC(ordered_params, N, seed = None):\n",
    "\n",
    "    if seed is None:\n",
    "        seed = int(time())\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    points = []\n",
    "    # by linspacing each parameter and shuffling, I ensure there is only one point in each row, in each dimension.\n",
    "    for plow, phigh in ordered_params.itervalues():\n",
    "        point = np.linspace(plow, phigh, num=N)\n",
    "        np.random.shuffle(point)  # makes the cube random.\n",
    "        points.append(point)\n",
    "    return np.stack(points).T\n",
    "\n",
    "\n",
    "def add_logMmin(hod_params, cat):\n",
    "\n",
    "    hod_params['logMmin'] = 13.0 #initial guess\n",
    "    #cat.populate(hod_params) #may be overkill, but will ensure params are written everywhere\n",
    "    def func(logMmin, hod_params):\n",
    "        hod_params.update({'logMmin':logMmin})\n",
    "        return (cat.calc_analytic_nd(hod_params, min_ptcl = min_ptcl) - nd)**2\n",
    "\n",
    "    res = minimize_scalar(func, bounds = logMmin_bounds, args = (hod_params,), options = {'maxiter':100}, method = 'Bounded')\n",
    "\n",
    "    # assuming this doens't fail\n",
    "    #print 'logMmin', res.x\n",
    "    hod_params['logMmin'] = res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pearce.mocks.kittens import TestBox\n",
    "cat = TestBox(boxno = 0, realization = 0, system = 'ki-ls')\n",
    "cat.load(1.0, HOD='zheng07', particles = True, downsample_factor = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO seed here for constant HODs\n",
    "# TODO maybe just do 5, 10 may be overkill\n",
    "N = 10\n",
    "LHC = make_LHC(hod_param_ranges, N, 24)\n",
    "hod_dicts = [dict(zip(hod_param_ranges.keys(), vals)) for vals in LHC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/ki/swmclau2/.local/lib/python2.7/site-packages/halotools-0.7.dev5005-py2.7-linux-x86_64.egg/halotools/empirical_models/phase_space_models/analytic_models/monte_carlo_helpers.py:205: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  self.rad_prof_func_table_indices[digitized_param_list]\n",
      "/u/ki/swmclau2/.local/lib/python2.7/site-packages/halotools-0.7.dev5005-py2.7-linux-x86_64.egg/halotools/empirical_models/phase_space_models/analytic_models/monte_carlo_helpers.py:522: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  self.rad_prof_func_table_indices[digitized_param_list]\n"
     ]
    }
   ],
   "source": [
    "cat.populate(hod_dicts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ombh2', 'omch2', 'w0', 'ns', 'ln10As', 'H0', 'Neff'],\n",
       " array([ 2.32629e-02,  1.07830e-01, -7.26513e-01,  9.80515e-01,\n",
       "         3.03895e+00,  6.32317e+01,  2.95000e+00]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat._get_cosmo_param_names_vals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from halotools.mock_observables import return_xyz_formatted_array, delta_sigma, tpcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_ds(cat, bins):\n",
    "    #n_cores = self._check_cores(n_cores)\n",
    "    n_cores = 2\n",
    "    \n",
    "    x_g, y_g, z_g = [cat.model.mock.galaxy_table[c] for c in ['x', 'y', 'z']]\n",
    "    pos_g = return_xyz_formatted_array(x_g, y_g, z_g, period=cat.Lbox)\n",
    "\n",
    "    x_m, y_m, z_m = [cat.halocat.ptcl_table[c] for c in ['x', 'y', 'z']]\n",
    "    pos_m = return_xyz_formatted_array(x_m, y_m, z_m, period=cat.Lbox)\n",
    "\n",
    "    rp_bins = bins #if not angular else self._rp_from_ang(bins)\n",
    "\n",
    "    # Halotools wnats downsampling factor defined oppositley\n",
    "    # TODO verify little h!\n",
    "    # TODO maybe split into a few lines for clarity\n",
    "    return delta_sigma(pos_g / cat.h, pos_m / cat.h, cat.pmass / cat.h,\n",
    "                   downsampling_factor=1. / cat._downsample_factor, rp_bins=rp_bins,\n",
    "                   period=[10*cat.Lbox/cat.h, 10*cat.Lbox/cat.h, cat.Lbox / cat.h], num_threads=n_cores, cosmology=cat.cosmology)[1] / (1e12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "import pyccl as ccl\n",
    "from scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_ds_analytic(cat, bins, xi = None, rbins = None):    \n",
    "    n_cores = 1#self._check_cores(n_cores)\n",
    "    # calculate xi_gg first\n",
    "    xi_kwargs = {}\n",
    "    if xi is None:\n",
    "        assert rbins is None\n",
    "        _rbins = np.logspace(-2, 1.6, 21)\n",
    "        rbins = np.zeros((_rbins.shape[0]-1))\n",
    "        rbins[0] = _rbins[0]\n",
    "        rbins[1:] = _rbins[2:]\n",
    "        xi = cat.calc_xi_gm(rbins, n_cores=n_cores, **xi_kwargs)\n",
    "    else:\n",
    "        assert rbins is not None, \"Must specify rbins along with xi\"\n",
    "\n",
    "    if np.any(xi <= 0):\n",
    "        warnings.warn(\n",
    "            \"Some values of xi are less than 0. Setting to a small nonzero value. This may have unexpected behavior, check your HOD\")\n",
    "        xi[xi <= 0] = 1e-3\n",
    "\n",
    "    rpoints = (rbins[:-1] + rbins[1:]) / 2.0\n",
    "    xi_rmin, xi_rmax = rpoints[0], rpoints[-1]\n",
    "\n",
    "    # make an interpolator for integrating\n",
    "    xi_interp = interp1d(np.log10(rpoints), np.log10(xi))\n",
    "\n",
    "    # get the theotertical matter xi, for large scale estimates\n",
    "    names, vals = cat._get_cosmo_param_names_vals()\n",
    "    param_dict = {n: v for n, v in zip(names, vals)}\n",
    "    if 'omch2' in param_dict: # in other units, convert\n",
    "        new_param_dict = {}\n",
    "        new_param_dict['Omega_c'] = param_dict['omch2']/cat.h**2\n",
    "        new_param_dict['Omega_b'] = param_dict['ombh2']/cat.h**2\n",
    "        new_param_dict['n_s'] = param_dict['ns']\n",
    "        new_param_dict['h'] = cat.h\n",
    "        new_param_dict['A_s'] = np.exp(param_dict['ln10As'])/(np.power(10, 10))\n",
    "\n",
    "        param_dict = new_param_dict\n",
    "\n",
    "    \n",
    "    elif 'Omega_c' not in param_dict:\n",
    "        param_dict['Omega_c'] = param_dict['Omega_m'] - param_dict['Omega_b']\n",
    "        del param_dict['Omega_m']\n",
    "\n",
    "    cosmo = ccl.Cosmology(**param_dict)\n",
    "\n",
    "    big_rbins = np.logspace(1, 2.3, 21)\n",
    "    big_rpoints = (big_rbins[1:] + big_rbins[:-1]) / 2.0\n",
    "    big_xi_rmax = big_rpoints[-1]\n",
    "    xi_mm = ccl.correlation_3d(cosmo, cat.a, big_rpoints)\n",
    "\n",
    "    xi_mm[xi_mm < 0] = 1e-6  # may wanna change this?\n",
    "    xi_mm_interp = interp1d(np.log10(big_rpoints), np.log10(xi_mm))\n",
    "\n",
    "    # correction factor\n",
    "    bias = np.power(10, xi_interp(1.2) - xi_mm_interp(1.2))\n",
    "    rhocrit = cat.cosmology.critical_density(0).to('Msun/(Mpc^3)').value\n",
    "    rhom = cat.cosmology.Om(0) * rhocrit * 1e-12  # SM h^2/pc^2/Mpc; integral is over Mpc/h\n",
    "\n",
    "    def sigma_integrand_medium_scales(lRz, Rp, xi_interp):\n",
    "        Rz = np.exp(lRz)\n",
    "        #print \"Med\", Rz, Rp, rpoints[0]\n",
    "        return Rz * 10 ** xi_interp(np.log10(Rz * Rz + Rp * Rp) * 0.5)\n",
    "\n",
    "    def sigma_integrand_large_scales(lRz, Rp, bias, xi_mm_interp):\n",
    "        Rz = np.exp(lRz)\n",
    "        #print \"Large\", Rz, Rp, rpoints[0]\n",
    "        return Rz * bias * 10 ** xi_mm_interp(np.log10(Rz * Rz + Rp * Rp) * 0.5)\n",
    "\n",
    "    ### calculate sigma first###\n",
    "\n",
    "    sigma_rpoints = np.logspace(-1.5, 2.2, 15)\n",
    "\n",
    "    sigma = np.zeros_like(sigma_rpoints)\n",
    "    for i, rp in enumerate(sigma_rpoints):\n",
    "        log_u_ss_max = np.log(xi_rmax ** 2 - rp ** 2) / 2.0  # Max distance to integrate to\n",
    "        log_u_ls_max = np.log(big_xi_rmax ** 2 - rp ** 2) / 2.0  # Max distance to integrate to\n",
    "\n",
    "        if not np.isnan(log_u_ss_max):  # rp > xi_rmax\n",
    "            small_scales_contribution = \\\n",
    "                    quad(sigma_integrand_medium_scales, -10, log_u_ss_max, args=(rp, xi_interp))[0]\n",
    "            Rz = np.exp(log_u_ls_max)\n",
    "\n",
    "            large_scales_contribution = quad(sigma_integrand_large_scales, log_u_ss_max, log_u_ls_max, \\\n",
    "                                             args=(rp, bias, xi_mm_interp))[0]\n",
    "        elif not np.isnan(log_u_ls_max):\n",
    "            small_scales_contribution = 0\n",
    "            large_scales_contribution = quad(sigma_integrand_large_scales, np.log(xi_rmax), log_u_ls_max, \\\n",
    "\n",
    "                                                                                              args=(rp, bias, xi_mm_interp))[0]\n",
    "        else:\n",
    "            small_scales_contribution = large_scales_contribution = 0.0\n",
    "\n",
    "        assert not any(np.isnan(c) for c in\n",
    "                       (small_scales_contribution, large_scales_contribution)), \"NaN found, aborting calculation\"\n",
    "        sigma[i] = (small_scales_contribution + large_scales_contribution) * rhom * 2;\n",
    "\n",
    "    sigma_interp = interp1d(np.log10(sigma_rpoints), sigma)\n",
    "\n",
    "    ### calculate delta sigma ###\n",
    "\n",
    "    def DS_integrand_medium_scales(lR, sigma_interp):\n",
    "        #print 'DS', np.exp(lR), rp_points[0]\n",
    "        return np.exp(2 * lR) * sigma_interp(np.log10(np.exp(lR)))\n",
    "\n",
    "    rp_bins = bins #if not angular else cat._rp_from_ang(bins)\n",
    "\n",
    "    rp_points = (rp_bins[1:] + rp_bins[:-1]) / 2.0\n",
    "    lrmin = np.log(sigma_rpoints[0])\n",
    "    ds = np.zeros_like(rp_points)\n",
    "\n",
    "    for i, rp in enumerate(rp_points):\n",
    "        result = quad(DS_integrand_medium_scales, lrmin, np.log(rp), args=(sigma_interp,))[0]\n",
    "        print i, np.exp(lrmin),  rp, result * 2 / (rp ** 2),  sigma_interp(np.log10(rp))\n",
    "# print result, rp, sigma_interp(np.log10(rp))\n",
    "        ds[i] = result * 2 / (rp ** 2) - sigma_interp(np.log10(rp))\n",
    "\n",
    "    return xi, sigma, ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rp_bins = np.logspace(-1.0, 1.6, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names, vals = cat._get_cosmo_param_names_vals()\n",
    "param_dict = {n: v for n, v in zip(names, vals)}\n",
    "\n",
    "new_param_dict = {}\n",
    "new_param_dict['Omega_c'] = param_dict['omch2']/cat.h**2\n",
    "new_param_dict['Omega_b'] = param_dict['ombh2']/cat.h**2\n",
    "new_param_dict['n_s'] = param_dict['ns']\n",
    "new_param_dict['h'] = cat.h\n",
    "new_param_dict['A_s'] = np.exp(param_dict['ln10As'])/(np.power(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'H0': 63.2317,\n",
       " 'Neff': 2.95,\n",
       " 'ln10As': 3.03895,\n",
       " 'ns': 0.9805149999999999,\n",
       " 'ombh2': 0.023262900000000003,\n",
       " 'omch2': 0.10783,\n",
       " 'w0': -0.726513}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A_s': 2.088330424967889e-09,\n",
       " 'Omega_b': 0.058182735712595794,\n",
       " 'Omega_c': 0.2696931333535029,\n",
       " 'h': 0.632317,\n",
       " 'n_s': 0.9805149999999999}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1       ,  0.13945832,  0.19448624,  0.27122726,  0.37824899,\n",
       "        0.52749971,  0.73564225,  1.02591437,  1.43072299,  1.99526231,\n",
       "        2.7825594 ,  3.88051073,  5.41169527,  7.54705957, 10.52500285,\n",
       "       14.67799268, 20.46968272, 28.54667663, 39.81071706])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:79: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:82: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:79: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:82: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:79: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:82: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:79: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:82: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:79: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:82: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:79: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:82: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:79: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:82: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:79: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:82: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:82: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:82: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:82: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:82: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0316227766016838 0.11972916245978728 127.76564964804146 92.74372223112209\n",
      "1 0.0316227766016838 0.1669722844066554 103.18687006073039 64.69121357006642\n",
      "2 0.0316227766016838 0.23285675091346955 77.95772298146079 43.417942973135865\n",
      "3 0.0316227766016838 0.3247381242860707 57.17020818534411 28.55687948778518\n",
      "4 0.0316227766016838 0.4528743485046003 40.28917438559078 18.91976649832625\n",
      "5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:86: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:109: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0316227766016838 0.6315709804149516 27.958812414436387 11.69336337464052\n",
      "6 0.0316227766016838 0.8807783099648259 18.93947248828037 7.971546798629854\n",
      "7"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:109: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:109: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0316227766016838 1.2283186773318842 12.768625224124092 4.89468195363011\n",
      "8 0.0316227766016838 1.712992652081319 8.626243720808576 3.7189777386439307\n",
      "9"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:109: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:109: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0316227766016838 2.3889108585880026 5.933096402286645 2.6710429728706537\n",
      "10 0.0316227766016838 3.3315350672086548 4.207756880049089 2.1497934895075983\n",
      "11"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:109: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:109: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0316227766016838 4.646102998837411 3.0746247263545436 1.692937162914021\n",
      "12 0.0316227766016838 6.4793774162167725 2.3103120459995306 1.3478370039438554\n",
      "13"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:109: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:109: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0316227766016838 9.036031209873123 1.7569903049867 1.0488757226758012\n",
      "14 0.0316227766016838 12.601497764499022 1.3431315483904651 0.7898732727935609\n",
      "15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:109: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:109: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0316227766016838 17.57383769714796 1.0144618213294088 0.58014451917124\n",
      "16 0.0316227766016838 24.508179676527277 0.7524340523924141 0.3909131581892916\n",
      "17 0.0316227766016838 34.17869684516453 0.5302286789873151 0.2200743954283325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/slac.stanford.edu/u/ki/swmclau2/.local/lib/python2.7/site-packages/ipykernel/__main__.py:109: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n"
     ]
    }
   ],
   "source": [
    "xi, sigma, ds_analytic = calc_ds_analytic(cat, rp_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = calc_ds(cat, rp_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rpoints = (rp_bins[1:] + rp_bins[:-1])/2.0\n",
    "plt.plot(rpoints, ds.squeeze(), label = 'Halotools')\n",
    "plt.plot(rpoints, ds_analytic.squeeze(), label = 'Analytic')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.loglog();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
